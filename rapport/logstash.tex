\begin{figure}[H]
\center
\includegraphics[width=0.2\textwidth]{logstash.png}
\label{fig:logstashlogo.png}
\end{figure}
\section{Présentation de Logstash}

Logstash permet de traiter et/ou de transférer des données en masse. Dans notre 
projet, nous l'utiliserons essentiellement en conjonction avec Elasticsearch. 
Cependant, et comme le montre l'abondante liste de ses plugins d'output\footnote{expliqué
après}, Logstash est capable de fonctionner avec de nombreux autres logiciels et donc
de s'intégrer à de nombreuses piles logicielles.
Dans notre projet, c'est lui qui centralisera les \gls{logs} et les traitera (éclatera)
afin qu'ils soient plus facilement exploitable par Elasticsearch.


\subsection{Pourquoi Logstash?}
Bien qu'un administrateur système compétent soit capable d'analyser de façon rapide 
et efficace les logs d'une machine (à l'aide de perl,awk,sed,tail,grep\ldots), cette méthode
est fastidieuse. De plus, face à des dizaines/milliers de machines (virtuelles aussi), 
cette méthode de travail n'est plus applicable.
Il devient de plus en plus fréquent (cloud, applications multicouches\ldots) 
que les logs d'une seule machine ne suffisent pas à diagnostiquer convenablement un 
problème.

C'est pour centraliser tout types de \gls{logs} que Logstash a été créé, nous
l'utiliserons surtout pour sa vélocité et sa grande synergie avec Elasticsearch.

\subsection{Fonctionnement interne}
Logstash est un logiciel développé en Jruby\footnote{sauf mention contraire, on supposera
dans ce rapport que logstash est développé en ruby} (Jruby est en faite une implémentation
de ruby 1.8 en Java qui était à l'époque plus rapide que ruby "seul"). 
L'utilisation de Logstash s'articule autour de 3 \emph{blocs} 
également appelés \emph{stages} (phase).
\begin{itemize}
    \item   Le bloc : \emph{Inputs} génère des événements à partir des informations reçues
    par logstash en entrée.
    \item   Le bloc : \emph{Filters} modifie, manipule, ces évènements dans logstash
    \item   Le bloc : \emph{Outputs} envoie les évènements de logstash vers leur 
    prochaine destination.
\end{itemize}
Explications sur \textbf{l'implémentation du passage entre les blocs} ainsi que
\textbf{la tolérance de pannes}, et le\textbf{ multithread} dans Logstash à 
consulter p\pageref{subsec:passageinterbloc}.\\[2mm]

Dans chaque blocs on peut utiliser une multitude de plugins. Ce sont des modules 
\textbf{indépendants} qui peuvent également fonctionner en \textbf{conjonction} les uns des autres.

Il est, par exemple, possible de configurer le bloc \emph{inputs} pour utiliser 
plusieurs fois le plugin "file" (fonctionnement expliqué p\pageref{lst:conflogstashiniteloop}) 
et de se servir dans le même temps d'un autre plugin du bloc \emph{inputs} : stdin 
qui prendra typiquement en entrée le clavier.


Il est possible d'implémenter de nouveaux plugins en ruby afin de les ajouter à
notre Logstash, c'est expliqué dans la documentation. 

Explications sur les \textbf{codecs} un type de bloc à part p\pageref{subsec:logstashcodec}




%Consulter la partie sur le \textbf{multithread} p\pageref{subsec:logstashmultithread}


\section{Installation}
%Sur debian il n'existe pas de paquet deb déjà fait, et le seul prérequis 
%est d'avoir une version de java > 1.7.0\_45
%Pour télécharger et installer
%curl -O https://download.elasticsearch.org/logstash/logstash/logstash-1.4.2.tar.gz
%
%tar zxvf logstash-1.4.2.tar.gz
%
%script before-install.sh
%
%sudo cp -r /home/\$USER/Downloads/logstash-1.4.2 /opt/logstash
%
%sudo mkdir /var/log/logstash
%
%script after-install.sh
%
%cd logstash-1.4.2
%
%Création du path
%
%export PATH+=:/opt/logstash
%
%Dautres méthodes d'installation

%Ensuite un simple git clone https://github.com/elastic/logstash.git
%nous permet de récupérer le dépot stable le plus récent.
%Enfin des scripts d'installation sont disponible
%dans logstash/pkg/debian



Sur Debian Jessie, il n'existe pas de paquet officiel Logstash maintenu. Il existe,
en revanche, un paquet tiers\fnu{https://download.elastic.co/logstash/logstash/packages/debian/logstash\_1.4.2-1-2c0f5a1\_all.deb}
fourni par l'éditeur du logiciel. Attention, le paquet nécessite l'ajout de dépendances manuelles\footnote{wget paquet, 
dpkg -i paquet, apt-get install -f} ainsi qu'un rechargement de 
la configuration des services : \emph{systemctl daemon-reload}.

Les dépendances nécessaires sont \emph{jruby} et \emph{openjdk-7-jre}, les mêmes 
que pour elasticsearch.

Une autre manière de réaliser l'installation est d'ajouter les dépots logstash à 
\ipath{/etc/apt/source.list.d/logstash.list.d/logstash.list}

\begin{lstlisting}[style=code,label={lst:ajoutdepotlogstash}]
deb https://packages.elasticsearch.org/logstash/1.4/debian stable main
\end{lstlisting}

et évidemment la clef qui va bien\footnote{permet d'authentifier les paquets téléchargés
(cf:SecureApt)}

\begin{lstlisting}[style=code,label={lst:ajoutclefdepotlogstash}]
wget -qO - https://packages.elasticsearch.org/GPG-KEY-elasticsearch | sudo apt-key add -
\end{lstlisting}

\subsection{Configurations}
Il est d'usage dans une installation \textit{propre} de créer un utilisateur spécifique
à notre utilisation. C'est également le cas dans notre paquet. L'administrateur 
système doit donner à cet utilisateur, nouvellement créé les droits nécessaires 
pour qu'il puisse faire son travail correctement. Dans le cadre de 
l'analyse de logs, faire de l'utilisateur logstash un membre du groupe \emph{adm}. 
Le groupe d'administration de Debian lui permettra, par exemple, d'avoir accès en 
lecture à la plupart des fichiers de \ipath{/var/log/}.

\subsubsection{Set Capabilities}
Cependant, cette façon de faire peut ne pas être suffisante.
Notre utilisation de logstash consiste, entre autre, à centraliser les \gls{logs}. 
Ces derniers sont généralement envoyés par l'intermédiaire de syslog (RFC 5244).
Par défaut, syslog utilise le port 514. Ce port, inférieur à 1024, est donc \textit{privilégié}.
Aussi, seul \emph{root} a le droit d'écouter ces ports. Ajouter notre utilisateur 
logstash au groupe root enlèverait le bénéfice de sécurité obtenu en isolant les 
utilisateurs en fonction de leurs besoins. Nous allons plutôt utiliser les 
\emph{capabilities}\fnu{http://man7.org/linux/man-pages/man7/capabilities.7.html} 
et la commande \emph{setcap}\fnu{https://github.com/elastic/logstash/issues/1587}
\begin{lstlisting}[style=code,label={lst:setcapabilities}]
setcap cap_net_bind_service=+epi /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java
setcap cap_net_bind_service=+epi /usr/lib/jvm/java-1.7.0-openjdk-amd64/jre/bin/java
\end{lstlisting}
qui permettent à un processus (thread en faite) de ne pas se soumettre à certaines 
vérifications de sécurité du noyau.\\[2mm]
Des informations plus précise concernant \textbf{la mise en œuvre des capabilities}
p\pageref{subsec:logstashcapabilities}

\section{Grammaire et conjugaison}
\subsection{Généralités}
Dans cette section, nous expliquerons le fonctionnement de la syntaxe du fichier de 
configuration de Logstash.\fnu{http ://logstash.net/docs/1.4.2/configuration}

Le (ou les fichiers) de configuration comportent deux ou trois parties, représentant 
les blocs dont nous avons déjà parlé. Le bloc \emph{filter} est optionnel.
Il est important de noter que, s'il est possible de répartir sa configuration dans
plusieurs fichiers. Ces fichiers seront concaténés (attention aux boucles infinies
dans ce cas là).

\begin{lstlisting}[style=logstash,label={lst:conflogstashminimale},caption={Configuration minimale}]
input {
    stdin{}#ceci est un plugin
}

#filter {
#}#on peut également commenter en fin de ligne

output {
    stdout{}#ceci est un autre plugin
}
\end{lstlisting}

On utilise dans ce code les plugins stdin et stdout. Comme leur nom et leur emplacement
dans le fichier de configuration peuvent le laisser supposer,
Logstash collecte en entrée tout ce qui vient de l'entrée standard, typiquement
le clavier, et l'envoie sur la sortie standard, typiquement, un terminal.

Pour voir le contenu de l'output, il ne faut pas utiliser Logstash en mode dæmon 
et donc utiliser, l'option flag -f et séléctionner le fichier de configuration.


Dans ce second exemple, plus complexe, nous allons présenter une utilisation plus
vaste des plugins et la logique sous-jacente à leur utilisation.

\begin{lstlisting}[style=logstash,label={lst:conflogstashiniteloop},caption={Infinite loop}]
#mail.conf
input {
    file {
        path => ["/home/fdupont/testmail"]
    }
}

filter{
    throttle{
        before_count => 2
        after_count => 4
        period => 120
        key => "%{message}"
        add_tag => "contenu"
    }
}

output {
    stdout{ }
    if "contenu" not in [tags]{
        email{
            to => "fdupont@localhost"
            from => "logstash@%{host}"
            subject => "%{message}"
            body => "Ceci est un test sur l'hote %{host}\n avec pour message : %{message}"
        }
    }
}

#shipping.conf
input {
    file {
        path => ["/var/log/secure", "/var/log/messages", "/var/log/*.log","/var/mail/fdupont"]
        exclude => ["*.gz"]
    }
    file {
        path => ["/var/mail/ldidry"]
    }
}


output {
    stdout{ }
    redis {
        host => "100.127.255.1"
        data_type => "list"
        key => "logstash"
    }
}
\end{lstlisting}

Cet exemple de code ne doit pas être utilisé : c'est une boucle infinie.
Il permet en revanche, d'expliquer de nombreux points de fonctionnement de la syntaxe
du fichier de configuration de Logstash.
Ce code représente, en fait, {\bfseries 2 fichiers}, mail.conf et shipping.conf, tous
deux situés dans le répertoire par défaut des fichiers de configuration de Logstash
\ipath{/etc/logstash/conf.d/}. Ils sont lus par ordre alphabétique et concaténés 
(comprendre que les inputs ainsi que les outputs sont fusionnés, il faut donc être
rigoureux dans leur écriture afin de ne pas créer d'effets de bord indésirables).
Une bonne pratique consiste, à utiliser la convention de nommage suivante : \textit{
00-description, 01-description} etc \ldots


Chacun possède un bloc input, output et l'un d'entre eux : filter.
Dans chacun des blocs, on trouve un ou plusieurs {\bfseries plugins} comme email, 
file, redis ou d'autres. 
Chacun de ces plugins possède son propre paramétrage, réglable au travers de 
directives, mais avec une syntaxe commune.


\begin{lstlisting}[style=logstash,label={lst:conflogstashsyntaxe1},caption={Syntaxe}]
    directive => int
    directive => "string"
    directive => ["membre", "de", "l'array"]
\end{lstlisting}

La plupart des directives de plugins se comportent ainsi, pas toutes. Nous
verrons quelques exemples dans des configurations plus avancées. Dans tout les cas, il
est indispensable de se référer à la documentation pour toute première utilisation d'un
plugin.


Comme montré dans le code \ref{lst:conflogstashsyntaxe1} il est également possible 
d'utiliser des structures conditionnelles (les if, else, else if, en faite).
De nombreux opérateurs sont également supportés: ==, !=, <, >, <=, >=, mais aussi
les expressions régulières (syntaxe ruby) =$\sim$, $\sim$! et enfin : in, not in,and,nand,
or,xor et !. 

Dans notre exemple de code \ref{lst:conflogstashiniteloop}, la structure conditionnelle
est utilisé pour faire le trie en utilisant les \emph{tags}.

Il est à noter, également, que les directives \textbf{path}, disponibles par exemple dans
le plugin file, prennent en compte le globbing et le globbing récursif 
(\ipath{le/chemin/*/.*log}).

\subsubsection{Autopsie d'une la boucle infinie}
La configuration \ref{lst:conflogstashiniteloop}, qui ne fonctionne pas
correctement, n'a pas été mise là par hasard. Cette erreur, permet de bien comprendre 
le fonctionnement des fichiers de configuration de Logstash.

Rappels : Il y a dans cette configuration, 2 fichiers de configuration. Les fichiers,
sont concaténés au lancement de Logstash de telle sorte que virtuellement cela donnerait 
un résultat similaire à :


\begin{lstlisting}[style=logstash,label={lst:conflogstashiniteloop2},caption={Infinite loop concaténé}]
#mail.conf
input {
    file {
        path => ["/home/fdupont/testmail"]
    }
    file {
        path => ["/var/log/secure", "/var/log/messages", "/var/log/*.log","/var/mail/fdupont"]
        exclude => ["*.gz"]
    }
    file {
        path => ["/var/mail/ldidry"]
    }
}

filter{
    throttle{
        before_count => 2
        after_count => 4
        period => 120
        key => "%{message}"
        add_tag => "contenu"
    }
}

output {
    stdout{ }
    if "contenu" not in [tags]{
        email{
            to => "fdupont@localhost"
            from => "logstash@%{host}"
            subject => "%{message}"
            body => "Ceci est un test sur l'hote %{host}\n avec pour message : %{message}"
        }
    }
    redis {
        host => "100.127.255.1"
        data_type => "list"
        key => "logstash"
    }
}
\end{lstlisting}

Ici, le problème semble plus évident l'output et l'input sont "liés". Des messages
peuvent être détectés et envoyés par mail à l'adresse \ipath{fdupont@localhost} (soit
l'équivalent de \ipath{/var/mail/fdupont}). Ce fichier est également écouté, ainsi que la 
plupart de fichiers de logs. Voilà la source des boucles infinies, assez facilement
reproductible si l'on n'est pas suffisamment rigoureux, et surtout si l'on travail 
sur plusieurs fichiers à la fois.

L'autre erreur majeure de ce fichier se situe à la ligne 27. Si le terme contenu 
n'est pas présent dans "tags" alors on envoie un mail. Le fonctionnement est l'inverse 
de celui suggérer par throttle. Ici, un mail est envoyé dès qu'un événement se produit
dans un fichier de log. Ce mail envoyé dans /var/mail/fdupont sera renvoyé dans cette
même adresse. Le contenu de l'événement se modifiera en permanence puisque le message
sera encapsulé dans son prédécesseur \ldots

\subsection{Expressions régulières et patterns}

\subsubsection{Les expressions régulières de Grok}
Le moteur d'expression régulière de ruby\footnote{Oniguruma, présenté p\pageref{subsec:logstashregexengine}} est très puissant. 
Nous allons ici présenter les \emph{named groups}, une fonctionnalité assez avancé présente dans ce moteur.

Ces derniers permettent avantageusement de ne pas utiliser les patterns, ou plutôt d'en créer
de nouveaux sans modifier les fichiers de Logstash.
{\footnotesize(Grok est le plugin dont on se servira le plus avec Logstash, c'est 
pour cela que nous prenons le temps de présenter son système d'expression régulière)}


\begin{lstlisting}[style=logstash,label={lst:grokregex1},caption={Named group}]
(?<nom_du_champ>Pattern) 
(?<username> [a-zA-Z0-9._-]+)
\end{lstlisting}

Grok créera rangera automatiquement une chaine de caractères, satisfaisant la contrainte 
\ipath{/[a-zA-Z0-9.\_-]+/}  dans un champ  username. 
Ce champ pourra être réutiliser ultérieurement par Logstash ou même Elasticsearch.

\subsubsection{Les patterns de Grok}
Logstash\footnote{certains patterns sont bien utilisables en dehors de grok} met en place un système très utile et très facile à utiliser de patterns 
(motifs). Ces patterns correspondent à des mots clefs représentant des expressions 
régulières ou bien des concaténations d'expressions régulières et/ou de patterns.

Pour mieux comprendre en voici quelques exemples. 

\begin{lstlisting}[style=logstash,label={lst:patternsexplication1},caption={Exemple de définition et d'utilisation de Patterns}]
CISCOMAC (?:(?:[A-Fa-f0-9]{4}\.){2}[A-Fa-f0-9]{4})
WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2})
COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2})

MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC})
\end{lstlisting}

On comprend bien en lisant le code précédent le fonctionnement des patterns : il est
très similaire à celui des \textit{named groups} : définition d'un nom, expression
régulière associée. 

On les utilise en invoquant leur nom entouré par \%{} 

Nous n'avons pas créé de nouveaux patterns pour notre projet et préféré l'utilisation
des expressions régulières (named groups). Cela reste cependant possible en modifiant les fichiers 
paramétrant ces patterns. Ils sont par défaut situés dans \ipath{/opt/logstash/patterns}.


\subsection{Les flags}
Les \emph{flags} sont les noms donnés aux paramètres que l'on peut donner au binaire
de Logstash.

\begin{itemize}
    \item -f : file, désigne le fichier de configuration à utiliser;
    \item -e : permet d'utiliser une chaine de caractères (depuis la console) pour
    pour configurer Logstash, à utiliser pour faire des tests de configuration simples;
    \item -w : filterworkers, comme expliqué plus haut, permet d'affecter plusieurs
    threads à la gestion des filtres. (par défaut 1);
    \item - -configtest : associé à -f \ipath{path/to/conffile} vérifie la syntaxe 
    du fichier de configuration.
\end{itemize}

Par défaut Logstash utilisera les fichiers de configuration présents dans \\ 
\ipath{/etc/logstash/conf.d/}, ils seront ouverts par ordre alphabétique.


\section{Utilisation}
Logstash peut s'intégrer dans une architecture simple ou très compliquée. En fonction
du cas il peut être utilisé dans plusieurs modes.


\subsection{La base}
Pour fonctionner Logstash doit recevoir des données en input, et les envoyer sur 
une destination d'output.
La configuration la plus simple consiste à lire l'input d'un clavier et à diriger 
son output sur la sortie standard. Cela à été montré dans une partie 
\hyperref[lst:conflogstashminimale]{précédente}.
Dans ce cas, une seule machine est impliquée, cela n'a d'utilité que pour une démonstration
et éventuellement des tests.

Logstash est parfois utilisé pour centralisé les logs en un seul point en attendant
une sauvegarde du fichier nouvellement créé.


\begin{lstlisting}[style=logstash,label={lst:conflogstashminimale2},caption={Un autre exemple de configuration minime}]
input {
    file {
        path => ["/var/log/mail/fdupont", "/var/log/mail/apache", "/var/log/mail/...", ]
    }
}

filter {
    #On peut imaginer faire de l'assainissement/standardisation de logs ici...
}

output {
    file {
        path => ["/var/log/logoftheday-%{+YYYY-MM-dd}.log", ]
    }
}
\end{lstlisting}
Ce genre de configuration bien qu'un peu exotique peut s'envisager dans le cas de
de petites infrastructures avec une simple réplication des logs pour la sauvegarde.
Ici on tirerai principalement avantage de la capacité de traitement de Logstash grace
à son bloc filtre.

Mais le plus souvent on utilise Logstash comme un serveur central, parfois pour d'autres
Logstash.
\subsection{Mon serveur central}
Notre configuration sera présentée dans la troisième partie, mais c'est ce genre 
de montage que nous utilisons pour le projet.

Ici l'idée est de faire pointer les syslogs configurés sur tous les équipements vers
un serveur, faisant tourné une instance de Logstash. Cette instance renvera ensuite 
le flux \textit{utile} vers sa destination, ici un Elasticsearch (après une préalable
mise en tampon dans un redis).
\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{stacksimple.png}
\label{fig:elkstack1}
\caption{Pile ELK}
\end{figure}

Ici logstash sert donc à trié et centralisé le flux il n'est strictosensus pas indispensable
on prend cependant de gros risque à envoyer tous nos logs d'un coup sur une machine
dont le but est d'analyser des logs, pas d'encaisser le flux. 
Ne pas utiliser ce genre d'infrastructure poserait probablement des problèmes I/O,
et empecherait la scalabilité à plus long terme. si la machine intermédiaire, le 
serveur central, ne peut plus encaiser la charge, il suffit d'en déployer un autre
et de diviser le flux des syslogs (et autres) entre ces deux serveurs \textit{centraux}.


\subsection{Monter à l'échelle}
Dans de très grosses structures, il est possible qu'il faille des infrastructures
encore plus complexes!

\begin{figure}[H]
\center
\includegraphics[width=0.8\textwidth]{logstashcomplex.jpg}
\label{fig:logstashcomplex}
\caption{Exemple de montage plus complexe}
{\footnotesize Image de : The Logstash Book}
\end{figure}

L'idée reste la même que dans l'infrstructure précédente, mais, on est passé en multicouche.
C'est à dire qu'on a séparé physiquement chaque partie de l'infrstructure. 

Une couche pour le \textit{cluster Elasticsearch}, une couche pour les \textit{tampons Redis}\ldots
Chaque couche utilise plusieurs instances de leur \textit{logiciel métier}, cette redondance empêche les
points de défaillance unique (single point of failure). Elle permet également une
plus grande \textit{scalabilité} horizontale. 

Autrement dit, si le besoin s'en fait
sentir, il est possible avec des changements de configuration minimes de d'ajouter
des machines dans nos couches. Il devient possible d'augmenter sans jamais l'éteindre 
complètement la capacité de traitement de notre infrstructure. C'est la base de la
haute disponibilité.

