\begin{figure}[H]
\center
\includegraphics[width=0.2\textwidth]{logstash.png}
\label{fig:logstashlogo.png}
\end{figure}
\section{Présentation de Logstash}

Logstash permet de traiter et/ou de transférer des données en masse. Dans notre 
projet, nous l'utiliserons essentiellement en conjonction avec Elasticsearch en 
utilitaire de sortie. Cependant,
et comme le montre la liste des ses abondants plugins d'output, Logstash est capable
de fonctionner avec de nombreux autres logiciels.

\subsection{Pourquoi Logstash?}
Bien qu'un administrateur système compétent soit capable d'analyser de façon rapide 
et efficace les logs d'une machine (à l'aide de perl,awk,sed,tail,grep\ldots), cette méthode
est fastidieuse. De plus, face à des dizaines/milliers de machines (virtuelles aussi), 
cette méthode de travail n'est plus applicable, elle ne peut pas passer à l'échelle.
De plus Il devient de plus en plus fréquent (cloud, applications multicouches\ldots) 
que les logs d'une seule machine ne suffisent pas à diagnostiquer convenablement un 
problème.

C'est pour centraliser tout types de \gls{logs} que logstash a été créé, nous
l'utiliserons surtout pour sa vélocité et sa grande synergie avec Elasticsearch.

\subsection{Fonctionnement interne}
L'utilisation de logstash est un pipeline qui s'articule autour de 3 \emph{blocs} 
également appelés \emph{stages} (phase).
\begin{itemize}
    \item   Le bloc : \emph{Inputs} génère des événements à partir des informations reçues
    par logstash en entrée.
    \item   Le bloc : \emph{Filters} modifie, manipule, ces évènements dans logstash
    \item   Le bloc : \emph{Outputs} envoie les évènements de logstash vers leur 
    prochaine destination.
\end{itemize}

Cette façon de fonctionner peut faire penser à \emph{iptables}.

Logstash est un logiciel développé en Jruby\footnote{sauf mention contraire, on supposera
dans ce rapport que logstash est développé en ruby} (Jruby est en faite une implémentation
de ruby 1.8 en Java qui était à l'époque plus rapide que ruby "seul"). 
Le passage d'une phase à l'autre est implémenté via les \emph{SizedQueue} de ruby. 
Elles sont dimensionnées pour contenir 20 éléments\footnote{appelés messages lorsqu'on parle de queues, on parle bien ici 
des \textbf{événements} logstash}, ce n'est pas paramétrable sans modifier le code 
source, c'est un choix délibéré. Ces queues ne sont pas conçues pour stocker des 
données à long terme. On verra plus tard que cela justifie l'utilisation d'un 
\textit{buffer}, comme \emph{Redis}\footnote{voir la sous partie sur la tolérence
de pannes ainsi que le chapitre consacré à Redis}.


Chaque bloc est composé d'une multitude de plugins. Ce sont des modules indépendants
qui peuvent également fonctionner en conjonction les uns des autres.

Il est, par exemple, possible de configurer le bloc \emph{inputs} pour utiliser 
plusieurs fois le plugin "file" (on imagine pour des cas d'utilisations différentes) 
et de se servir dans le même temps d'un autre plugin du bloc \emph{inputs} : stdin 
qui prendra typiquement en entrée le clavier.


Il est possible d'implémenter de nouveaux plugins en ruby afin de les ajouter à
notre logstash.

Il existe également un \textit{pseudo-bloc} qui peut s'insérer dans les autres, ce 
bloc, \emph{codec} permet là de gérer la \textit{représentation des données} c'est 
à dire qu'un codec est capable de lire ou d'écrire dans une syntaxe particulière 
comme par exemple rubydebug, collectd, ou, bien plus intéressant pour nous, netflow.

%wtf why?
%et les types ??


%Explications supplémentaires sur les filtres
% les plugins et les patterns par défaut?

\subsubsection{Tolérance de pannes}
Vos logs sont \textbf{importants}, les traiter efficacement est la raison d'être 
de Logstash. Il ne souhaite pas que vous en perdiez le moindre à cause d'un problème 
réseau ou d'une défaillance quelconque rendant la destination indisponible.
%cf pipeline.rb et base.rb dans github
Lors d'une indisponibilité, les plugins outputs tentent de renvoyer les événements 
vers leur destination. Si ce n'est pas possible le plugin arrête de lire sa queue 
tant que le message n'a pas pu être envoyé. Par effet domino, une fois la queue 
\textit{filtre => output} remplie, le bloc filtre, ne pouvant plus envoyer de nouveaux 
messages à la queue \textit{FO}. Le plugin du bloc filtre va également retenter 
d'envoyer ses messages, et refuser en attendant de lire les nouveaux arrivant dans 
la queue \textit{input => filtre}.
Si cette dernière venait à se remplir c'est le Logstash tout entier qui refuserait de 
traiter de nouvelles informations. Dans le meilleur des mondes, les expéditeurs de
données se comporteraient comme logstash et attendraient patiemment que le problème
se résolve. Malheureusement cela n'est pas toujours possible d'où l'importance d'un 
Redis en amont (ou en aval) afin de faire tampon.
\footnote{Il existe d'autres outils que Redis, (dont ce n'est pas la fonction
principale) pour réaliser ce travail, ils sont plus adapté mais aussi moins documentés
dans leur utilisation avec Logstash.}

\subsubsection{Multithread}
Attention ces informations sont pour le moment, \textit{Jeudi 16 Avril 2015}, correctes 
mais sont amenées à changer, notamment concernant les outputs.

Chaque plugin input utilise un \gls{thread}. Cela permet d'éviter les engorgements si  
certaines entrées sont plus longues à traiter que d'autres.

Le bloc filtre entier n'utilise, par défaut, qu'un seul thread, mais, il est possible 
d'augmenter le nombre de threads affectés au traitement des filtres avec le \gls{flag}
-w lors du démarrage de Logstash.

À l'heure actuelle, le bloc output de logstash ne peut utiliser qu'un seul thread.
Il lit donc sa queue de façon séquentielle.


\section{Installation}
%Sur debian il n'existe pas de paquet deb déjà fait, et le seul prérequis 
%est d'avoir une version de java > 1.7.0\_45
%Pour télécharger et installer
%curl -O https://download.elasticsearch.org/logstash/logstash/logstash-1.4.2.tar.gz
%
%tar zxvf logstash-1.4.2.tar.gz
%
%script before-install.sh
%
%sudo cp -r /home/\$USER/Downloads/logstash-1.4.2 /opt/logstash
%
%sudo mkdir /var/log/logstash
%
%script after-install.sh
%
%cd logstash-1.4.2
%
%Création du path
%
%export PATH+=:/opt/logstash
%
%Dautres méthodes d'installation

%Ensuite un simple git clone https://github.com/elastic/logstash.git
%nous permet de récupérer le dépot stable le plus récent.
%Enfin des scripts d'installation sont disponible
%dans logstash/pkg/debian



Sur Debian Jessie, il n'existe pas de paquet officiel logstash maintenu. Il existe,
en revanche, un paquet tiers\fnu{https://download.elastic.co/logstash/logstash/packages/debian/logstash\_1.4.2-1-2c0f5a1\_all.deb}
fourni par l'éditeur du logiciel. Le dit paquet n'est pas de très bonne facture  
puisqu'il nécessite l'ajout de dépendances manuelles\footnote{wget paquet, 
dpkg -i paquet, apt-get install -f} ainsi qu'un rechargement de 
la configuration des services : \emph{systemctl daemon-reload}.

Les dépendances nécessaires sont \emph{jruby} et \emph{openjdk-7-jre}, les mêmes 
que pour elasticsearch.

Une autre manière de réaliser l'installation est d'ajouter les dépots logstash à 
\ipath{/etc/apt/source.list.d/logstash.list.d/logstash.list}

\begin{lstlisting}[style=code,label={lst:ajoutdepotlogstash}]
deb https://packages.elasticsearch.org/logstash/1.4/debian stable main
\end{lstlisting}

et évidemment la clef qui va bien\footnote{permet d'authentifier les paquets téléchargés
(cf:SecureApt)}

\begin{lstlisting}[style=code,label={lst:ajoutclefdepotlogstash}]
wget -qO - https://packages.elasticsearch.org/GPG-KEY-elasticsearch | sudo apt-key add -
\end{lstlisting}

\subsection{Configurations}
Il est d'usage dans une installation \textit{propre} de créer un utilisateur spécifique
à notre utilisation. C'est également le cas dans notre paquet. L'administrateur 
système doit donner à cet utilisateur, nouvellement créé les droits nécessaires 
pour qu'il puisse faire son travail correctement correctement. Dans le cadre de 
l'analyse de logs, faire de l'utilisateur logstash un membre du groupe \emph{adm}. 
Le groupe d'administration de Debian lui permettra, par exemple, d'avoir accès en 
lecture à la plupart des fichiers de \ipath{/var/log/}.

\subsubsection{Set Capabilities}
Cependant, cette façon de faire peut ne pas être suffisante.
Notre utilisation de logstash consiste, entre autre, à centraliser les \gls{logs}. 
Ces derniers sont généralement envoyés par l'intermédiaire de syslog (RFC 5244).
Par défaut, syslog utilise le port 514. Ce port, inférieur à 1024, est donc \textit{privilégié}.
Aussi, seul \emph{root} a le droit d'écouter ces ports. Ajouter notre utilisateur 
logstash au groupe root enlèverait le bénéfice de sécurité obtenu en isolant les 
utilisateurs en fonction de leurs besoins. Nous allons plutôt utiliser les 
\emph{capabilities}\fnu{http://man7.org/linux/man-pages/man7/capabilities.7.html} 
et la commande \emph{setcap}\fnu{https://github.com/elastic/logstash/issues/1587}
\begin{lstlisting}[style=code,label={lst:setcapabilities}]
setcap cap_net_bind_service=+epi /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java
setcap cap_net_bind_service=+epi /usr/lib/jvm/java-1.7.0-openjdk-amd64/jre/bin/java
\end{lstlisting}
qui permettent à un processus (thread en faite) de ne pas se soumettre à certaines 
vérifications de sécurité du noyau.

\textbf{cap\_net\_bind\_service} permet à un utilisateur non privilégié (non root) 
d'écouter sur les ports privilégiés.

Les informations concernants les autres capabilities existantes sont disponibles dans
la page de manuel correspondante : \emph{man capabilities}.

\textbf{=+epi} signifie que l'on ajoute une \emph{capapbility} à un fichier. Plus 
précisement \textbf{=+} signifie que l'on écrase les droits précédents pour les remplacer
par les nouveaux. \textbf{e, p} et \textbf{i} sont la gradation de droits que l'on peut 
attribuer à un fichier avec les capabilities\fnu{https://www.kernel.org/pub/linux/libs/security/linux-privs/kernel-2.2/capfaq-0.2.txt}. 

\begin{itemize}
    \item \textbf{effective}: indique si la capability est utilisée actuellement
    \item \textbf{permited}: définit quelles capabilities sont autorisées pour un 
    processus donné
    \item \textbf{inherited}: permet de transmettre la capability à un autre programme
\end{itemize}
\textbf{Note}: par défaut, changer le propriétaire d'un fichier de root, à non root enlève
les capabilities associées à ce dernier\footnote{\scriptsize{http://stackoverflow.com/questions/17743062/changing-user-ids-for-assigning-additional-capabilities}}.

Pour vérifier les \textit{capabilities} d'un binaire, on utilise la commande 
\emph{getcap}.

\begin{lstlisting}[style=code,label={lst:getcapabilities}]
    getcap /bin/ping
    /bin/ping = cap_net_raw+ep
\end{lstlisting}

Pour enlever les capabilities, il faut utiliser la commande suivante.
\begin{lstlisting}[style=code,label={lst:unsetcapabilities}]
setcap cap_net_bind_service=-epi /usr/lib/jvm/java-1.7.0-openjdk-amd64/jre/bin/java
\end{lstlisting}

Enfin, il est possible, de donner le droit à un utilisateur non root, l'autorisation
de modifier certaines capabilities. Pour ce faire, il faut modifier le fichier \\[1mm]
\ipath{/etc/security/capability.conf}.





\section{Grammaire et conjugaison}
\subsection{Généralités}
Dans cette section, nous allons brièvement expliquer le fonctionnement de la syntaxe 
du fichier de configuration de Logstash.\fnu{http ://logstash.net/docs/1.4.2/configuration}

Le ou les fichiers de configuration comportent deux ou trois parties, représentant 
les blocs dont nous avons parlé au préalable. Le bloc \emph{filter} est optionnel
et il est important de noter que, s'il est possible de répartir sa configuration
dans plusieurs fichiers, cette dernière sera concaténée, attention aux boucles infinies
dans ce cas là.

\begin{lstlisting}[style=logstash,label={lst:conflogstashminimale},caption={Configuration minimale}]
input {
    stdin{}#ceci est un plugin
}

#filter {
#}#on peut également commenter en fin de ligne

output {
    stdout{}#ceci est un autre plugin
}
\end{lstlisting}

Ici, on constate l'utilisation des plugins stdin et stdout. Comme leur nom 
et leur emplacement dans le fichier de configuration peuvent le laisser supposer,
Logstash collecte en entrée tout ce qui vient de l'entrée standard, typiquement
le clavier, et l'envoie sur la sortie standard, typiquement, un terminal.
Pour pouvoir recevoir l'output, il est d'ailleurs conseillé d'utiliser, le flag -f
et de ne pas lancer logstash en mode dæmon.

Dans ce second exemple, plus complexe, nous allons présenter une utilisation plus
vaste des plugins et la logique sous-jacente à leur utilisation.

\begin{lstlisting}[style=logstash,label={lst:conflogstashiniteloop},caption={Infinite loop}]
#mail.conf
input {
    file {
        path => ["/home/fdupont/testmail"]
    }
}

filter{
    throttle{
        before_count => 2
        after_count => 4
        period => 120
        key => "%{message}"
        add_tag => "contenu"
    }
}

output {
    stdout{ }
    if "contenu" not in [tags]{
        email{
            to => "fdupont@localhost"
            from => "logstash@%{host}"
            subject => "%{message}"
            body => "Ceci est un test sur l'hote %{host}\n avec pour message : %{message}"
        }
    }
}

#shipping.conf
input {
    file {
        path => ["/var/log/secure", "/var/log/messages", "/var/log/*.log","/var/mail/fdupont"]
        exclude => ["*.gz"]
    }
    file {
        path => ["/var/mail/ldidry"]
    }
}


output {
    stdout{ }
    redis {
        host => "100.127.255.1"
        data_type => "list"
        key => "logstash"
    }
}
\end{lstlisting}

Cet exemple de code ne doit pas être utilisé : c'est une boucle infinie.
Il permet en revanche, d'expliquer de nombreux points de fonctionnement de la syntaxe
du fichier de configuration de Logstash.
Ce code représente, en faite, {\bfseries 2 fichiers}, mail.conf et shipping.conf, tout
deux situés dans le répertoire par défaut des fichiers de configuration de Logstash
\ipath{/etc/logstash/conf.d/}. Ils sont lus par ordre alphabétique et concaténés 
(comprendre que les inputs ainsi que les outputs sont fusionnés, il faut donc être
rigoureux dans leur écriture afin de ne pas créer d'effets de bord indésirables).
Une bonne pratique consiste, à utiliser la convention de nommage suivante : \textit{
00-description, 01-description} etc \ldots


Chacun possède un bloc input, output et l'un d'entre eux : filter.
Dans chacun des blocs, on trouve un ou plusieurs {\bfseries plugins} comme email, 
file, redis ou d'autres. 
Chacun de ces plugins possède son propre paramétrage, réglable au travers de 
directives, mais avec une syntaxe commune.


\begin{lstlisting}[style=logstash,label={lst:conflogstashsyntaxe1},caption={Syntaxe}]
    directive => int
    directive => "string"
    directive => ["membre", "de", "l'array"]
\end{lstlisting}

La plupart des directives de plugins se comportent ainsi, pas toutes. Nous
verrons quelques exemples dans des configurations plus avancées. Dans tout les cas, il
est indispensable de se référer à la documentation pour toute primo utilisation d'un
plugin.


Comme montré dans le code \ref{lst:conflogstashsyntaxe1} il est également possible 
d'utiliser des structures conditionnelles (les if, else, else if, en faite).
De nombreux opérateurs sont également supportés: ==, !=, <, >, <=, >=, mais aussi
les expressions régulières (syntaxe ruby) =$\sim$, $\sim$! et enfin : in, not in,and,nand,
or,xor et !. 

Dans notre exemple de code \ref{lst:conflogstashiniteloop}, la structure conditionnelle
est utilisé pour faire le trie en utilisant les \emph{tags}.

Il est à noter, également, que les directives \textbf{path}, disponibles par exemple dans
le plugin file, prennent en compte le globbing et le globbing récursif 
(\ipath{le/chemin/*/.*log}).

\subsubsection{Autopsie d'une la boucle infinie}
La configuration \ref{lst:conflogstashiniteloop}, qui ne fonctionne pas
correctement, n'a pas été mise là par hasard. Cette erreur, permet de bien comprendre 
le fonctionnement des fichiers de configuration de Logstash.

Rappels : Il y a dans cette configuration, 2 fichiers de configuration. Les fichiers,
sont concaténés au lancement de Logstash de telle sorte que virtuellement cela donnerait 
un résultat similaire à :


\begin{lstlisting}[style=logstash,label={lst:conflogstashiniteloop2},caption={Infinite loop concaténé}]
#mail.conf
input {
    file {
        path => ["/home/fdupont/testmail"]
    }
    file {
        path => ["/var/log/secure", "/var/log/messages", "/var/log/*.log","/var/mail/fdupont"]
        exclude => ["*.gz"]
    }
    file {
        path => ["/var/mail/ldidry"]
    }
}

filter{
    throttle{
        before_count => 2
        after_count => 4
        period => 120
        key => "%{message}"
        add_tag => "contenu"
    }
}

output {
    stdout{ }
    if "contenu" not in [tags]{
        email{
            to => "fdupont@localhost"
            from => "logstash@%{host}"
            subject => "%{message}"
            body => "Ceci est un test sur l'hote %{host}\n avec pour message : %{message}"
        }
    }
    redis {
        host => "100.127.255.1"
        data_type => "list"
        key => "logstash"
    }
}
\end{lstlisting}

Ici, le problème semble plus évident l'output et l'input sont "liés". Des messages
peuvent être détectés et envoyés par mail à l'adresse \ipath{fdupont@localhost} (soit
l'équivalent de \ipath{/var/mail/fdupont}). Ce fichier est également écouté, ainsi que la 
plupart de fichiers de logs. Voilà la source des boucles infinies, assez facilement
reproductible si l'on n'est pas suffisamment rigoureux, et surtout si l'on travail 
sur plusieurs fichiers à la fois.

L'autre erreur majeure de ce fichier se situe à la ligne 27. Si le terme contenu 
n'est pas présent dans "tags" alors on envoie un mail. Le fonctionnement est l'inverse 
de celui suggérer par throttle. Ici, un mail est envoyé dès qu'un événement se produit
dans un fichier de log. Ce mail envoyé dans /var/mail/fdupont sera renvoyé dans cette
même adresse. Le contenu de l'événement se modifiera en permanence puisque le message
sera encapsulé dans son prédécesseur \ldots

\subsection{Expressions régulières et patterns}
Les expressions régulières utilisées par Logstash dans le plugin grok utilisent le 
moteur Oniguruma dont les spécifications sont disponibles à cette 
\href{http://www.geocities.jp/kosako3/oniguruma/doc/RE.txt}{adresse}\footnote{http://www.geocities.jp/kosako3/oniguruma/doc/RE.txt, 
si des symboles \textbf{ \textyen} apparaissent vous avez probablement un problème d'UTF8 sur 
votre navigateur, ils correspondent à des \textbf{ \textbackslash}}.
Ruby n'utilise plus Oniguruma depuis la version 2.0 mais son fork Onigmo\footnote{
dixit Wikipédia https://en.wikipedia.org/wiki/Oniguruma}. Mais cette évolution ne
s'applique pas à Logstash puisque ce dernier est codé en Jruby.

\subsubsection{Les expressions régulières de Grok}
Ce moteur permet des manipulations avancées d'expressions régulières, ce n'est pas 
l'objet de ce projet de les présenter. Nous nous contenterons simplement d'utiliser
des syntaxes assez classiques d'expressions régulières à l'exception des named groups. 
Ces derniers permettent avantageusement de ne pas utiliser les patterns, ou plutôt d'en créer
de nouveaux sans modifier les fichiers de Logstash.
{\footnotesize(Grok est le plugin dont on se servira le plus avec Logstash, c'est 
pour cela que nous prenons le temps de présenter son système d'expression régulière)}


\begin{lstlisting}[style=logstash,label={lst:grokregex1},caption={Named group}]
(?<nom_du_champ>Pattern) 
(?<username> [a-zA-Z0-9._-]+)
\end{lstlisting}

Grok créera rangera automatiquement une chaine de caractères, satisfaisant la contrainte 
\ipath{/[a-zA-Z0-9.\_-]+/}  dans un champ  username. 
Ce champ pourra être réutiliser ultérieurement par Logstash ou même Elasticsearch.


\subsubsection{Les patterns}
Logstash mets en place un système très utile et très facile à utiliser de patterns 
(motifs). Ces patterns correspondent à des mots clefs représentant des expressions 
régulières ou bien des concaténations d'expressions régulières ou de patterns.

La compréhension des patterns est simple et presque instantanée si l'on connait les
expressions régulières.
\begin{lstlisting}[style=logstash,label={lst:patternsexplication1},caption={Exemple de définition et d'utilisation de Patterns}]
CISCOMAC (?:(?:[A-Fa-f0-9]{4}\.){2}[A-Fa-f0-9]{4})
WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2})
COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2})

MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC})
\end{lstlisting}

Grok peut également utiliser ces patterns mais leur fonctionnement est général dans
Logstash.
On comprends bien dans le code précédent le fonctionnement des patterns : il est
très similaire à celui des \textit{named groups} : définition d'un nom, expression
régulière associée. On les utilise en invoquant leur nom entouré par \%{} 
Il sont utilisables ensemble comme dans l'exemple ci-dessus avec les adresses MAC,
ou (beaucoup) plus bas dans l'explication du fonctionnement de l'architecture.

Nous n'avons pas créé de nouveaux patterns pour notre projet et préféré l'utilisation
des expressions régulières. Cela reste cependant possible en modifiant les fichiers 
paramétrant ces patterns. Ils sont par défaut situés dans \ipath{/opt/logstash/patterns}.



\subsection{Les flags}
Les \emph{flags} sont les noms donnés aux paramètres que l'on peut donner au binaire
de Logstash.

\begin{itemize}
    \item -f : file, désigne le fichier de configuration à utiliser
    \item -e : permet d'utiliser une chaine de caractères (depuis la console) pour
    pour configurer Logstash, à utiliser pour faire des tests de configuration simples.
    \item -w : filterworkers, comme expliqué plus haut, permet d'affecter plusieurs
    threads à la gestion des filtres. (par défaut 1)
    \item - -configtest : associé à -f \ipath{path/to/conffile} vérifie la syntaxe 
    du fichier de configuration.
\end{itemize}

Par défaut Logstash utilisera les fichiers de configuration présents dans \\ 
\ipath{/etc/logstash/conf.d/}, ils seront ouverts par ordre alphabétique.


\section{Utilisation}
Logstash peut s'intégrer dans une architecture simple ou très compliquée. En fonction
du cas il peut être utilisé dans plusieurs modes.


\subsection{La base}
Pour fonctionner Logstash doit recevoir des données en input, et les envoyer sur 
une destination d'output.
La configuration la plus simple consiste à lire l'input d'un clavier et à diriger 
son output sur la sortie standard. Cela à été montré dans une partie 
\hyperref[lst:conflogstashminimale]{précédente}.
Dans ce cas, une seule machine est impliquée, cela n'a d'utilité que pour une démonstration
et éventuellement des tests.

Logstash est parfois utilisé pour centralisé les logs en un seul point en attendant
une sauvegarde du fichier nouvellement créé.


\begin{lstlisting}[style=logstash,label={lst:conflogstashminimale2},caption={Un autre exemple de configuration minime}]
input {
    file {
        path => ["/var/log/mail/fdupont", "/var/log/mail/apache", "/var/log/mail/...", ]
    }
}

filter {
    #On peut imaginer faire de l'assainissement/standardisation de logs ici...
}

output {
    file {
        path => ["/var/log/logoftheday-%{+YYYY-MM-dd}.log", ]
    }
}
\end{lstlisting}
Ce genre de configuration bien qu'un peu exotique peut s'envisager dans le cas de
de petites infrastructures avec une simple réplication des logs pour la sauvegarde.
Ici on tirerai principalement avantage de la capacité de traitement de Logstash grace
à son bloc filtre.

Mais le plus souvent on utilise Logstash comme un serveur central, parfois pour d'autres
Logstash.
\subsection{Mon serveur central}
Notre configuration sera présentée dans la troisième partie, mais c'est ce genre 
de montage que nous utilisons pour le projet.

Ici l'idée est de faire pointer les syslogs configurés sur tous les équipements vers
un serveur, faisant tourné une instance de Logstash. Cette instance renvera ensuite 
le flux \textit{utile} vers sa destination, ici un Elasticsearch (après une préalable
mise en tampon dans un redis).
\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{stacksimple.png}
\label{fig:elkstack1}
\caption{Pile ELK}
\end{figure}

Ici logstash sert donc à trié et centralisé le flux il n'est strictosensus pas indispensable
on prend cependant de gros risque à envoyer tous nos logs d'un coup sur une machine
dont le but est d'analyser des logs, pas d'encaisser le flux. 
Ne pas utiliser ce genre d'infrastructure poserait probablement des problèmes I/O,
et empecherait la scalabilité à plus long terme. si la machine intermédiaire, le 
serveur central, ne peut plus encaiser la charge, il suffit d'en déployer un autre
et de diviser le flux des syslogs (et autres) entre ces deux serveurs \textit{centraux}.


\subsection{Monter à l'échelle}
Dans de très grosses structures, il est possible qu'il faille des infrastructures
encore plus complexes!

\begin{figure}[H]
\center
\includegraphics[width=0.8\textwidth]{logstashcomplex.jpg}
\label{fig:logstashcomplex}
\caption{Exemple de montage plus complexe}
{\footnotesize Image de : The Logstash Book}
\end{figure}

L'idée reste la même que dans l'infrstructure précédente, mais, on est passé en multicouche.
C'est à dire qu'on a séparé physiquement chaque partie de l'infrstructure. 

Une couche pour le \textit{cluster Elasticsearch}, une couche pour les \textit{tampons Redis}\ldots
Chaque couche utilise plusieurs instances de leur \textit{logiciel métier}, cette redondance empêche les
points de défaillance unique (single point of failure). Elle permet également une
plus grande \textit{scalabilité} horizontale. 

Autrement dit, si le besoin s'en fait
sentir, il est possible avec des changements de configuration minimes de d'ajouter
des machines dans nos couches. Il devient possible d'augmenter sans jamais l'éteindre 
complètement la capacité de traitement de notre infrstructure. C'est la base de la
haute disponibilité.

