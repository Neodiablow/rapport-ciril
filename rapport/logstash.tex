\begin{figure}[H]
\center
\includegraphics[width=0.2\textwidth]{logstash.png}
\label{fig:logstashlogo.png}
\end{figure}
\section{Présentation de Logstash}

\subsection{Pourquoi Logstash?}
Bien qu'un administrateur système compétent soit capable d'analyser de façon rapide 
et efficace les logs d'une machine (à l'aide deperl+awk+sed+tail+grep), cette méthode
est fastidieuse. De plus, face à des dizaines/milliers de machines (virtuelles aussi), 
cette méthode n'est plus applicable, elle ne peut pas passer à l'échelle.
Il est actuellement fréquent (cloud, applications multicouche, \ldots) que les logs 
d'une seule machine ne suffise plus à diagnostiquer le problème auquel on est confronté.

\subsection{Fonctionnement interne}
L'utilisation de logstash est un pipeline qui s'articule autour de 3 \emph{blocs} 
également appelés \emph{stages} (phase).
\begin{itemize}
    \item   Le bloc : \emph{Inputs} génère des événements à partir des informations reçues
    par logstash en entrée.
    \item   Le bloc : \emph{Filters} modifie, manipule, ces évènements dans logstash
    \item   Le bloc : \emph{Outputs} envoie les évènements de logstash vers leur 
    prochaine destination.
\end{itemize}

Cette façon de fonctionner peut faire penser à \emph{iptables}.

Logstash est un logiciel développé en Jruby\footnote{sauf mention contraire, on supposera
dans ce rapport que logstash est développé en ruby} (Jruby est en faite une implémentation
de ruby 1.8 en Java qui était à l'époque plus rapide que ruby "seul"). 
Le passage d'une phase à l'autre est implémenté via les \emph{SizedQueue} de ruby. 
Elles sont dimensionnées pour contenir 20 éléments\footnote{appelés messages lorsqu'on parle de queues, on parle bien ici 
des \textbf{événements} logstash}, ce n'est pas paramétrable sans modifier le code 
source, c'est un choix délibéré. Ces queues ne sont pas conçues pour stocker des 
données à long terme. On verra plus tard que ce la justifie l'utilisation d'un 
\textit{buffer}, comme \emph{Redis}\footnote{voir la sous partie sur la tolérence
de pannes ainsi que le chapitre consacré à Redis}.


Chaque bloc est composé d'une multitude de plugins. Ce sont des modules indépendants
qui peuvent également fonctionner en conjonction les uns des autres.

Il est, par exemple, possible de configure le bloc \emph{inputs} pour utiliser 
plusieurs fois le plugin "file" (on imagine pour des cas d'utilisation différents) 
et de se servir dans le même temps d'un autre plugin du bloc \emph{inputs} : stdin 
qui prendra typiquement en entrée le clavier.


Il est possible d'implémenter de nouveaux plugins en ruby afin de les ajouter à
notre logstash.

Il existe également un \textit{pseudo-bloc} qui peut s'insérer dans les autres, ce 
bloc, \emph{codec} permet la de gérer la \textit{représentation des données} c'est 
à dire qu'un codec est capable de lire ou d'écrire dans une syntaxe particulière 
comme par exemple rubydebug, collectd, ou, bien plus intéressant pour nous, netflow.

%wtf why?
%et les types ??


%Explications supplémentaires sur les filtres
% les plugins et les patterns par défaut?

\subsubsection{Tolérance de pannes}
Vos logs sont \textbf{importants}, c'est la raison d'être de Logstash, il ne souhaite 
pas que vous en perdiez le moindre à cause d'un problème réseau ou d'une défaillance
quelconque rendant la destination indisponible.
%cf pipeline.rb et base.rb dans github
Lors d'une indisponibilité, les plugins outputs tentent de renvoyer les événements 
vers leur destination. Si ce n'est pas possible le plugin arrête de lire sa queue 
tant que le message n'a pas pu être envoyé. Par effet domino, une fois la queue 
\textit{filtre => output} remplie, le bloc filtre, ne pouvant plus envoyer de nouveaux 
messages à la queue \textit{FO}. Le plugin du bloc filtre va également retenter 
d'envoyer ses messages, et refuser en attendant de lire les nouveaux arrivant dans 
la queue \textit{input => filtre}.
Si cette dernière venait à se remplir c'est le Logstash tout entier qui refuserait de 
traiter de nouvelles informations. Dans le meilleur des mondes, les expéditeurs de
données se comporterais comme logstash et attendraient patiemment que le problème
se résolve, malheureusement cela n'est pas toujours possible, particulièrement dans
nos problématiques d'où l'importance d'un Redis en amont (ou en aval) afin de 
faire tampon.\footnote{Il existe d'autres outils que Redis, (dont ce n'est pas la fonction
principale) pour réaliser ce travail, ils sont plus adapté mais aussi moins documentés
dans leur utilisation avec logstash.}

\subsubsection{Multithread}
Attention ces informations sont pour le moment, \date{Jeudi 16 Avril}, correctes 
mais sont amenées à changer, notamment concernant les outputs.

Chaque plugin utilise input un \gls{thread}, cela permet d'éviter les engorgements si  
certaines entrées sont plus longues à traiter que d'autres.

En le bloc filtre entier n'utilise par défaut qu'un seul thread, mais il est possible 
d'augmenter le nombre de threads affectés au traitement des filtres avec le \gls{flag}
-w lors du démarrage de Logstash.

À l'heure actuelle le bloc output de logstash ne peut utiliser qu'un seul thread.
Il lit donc sa queue de façon séquentielle.


\section{Installation}
%Sur debian il n'existe pas de paquet deb déjà fait, et le seul prérequis 
%est d'avoir une version de java > 1.7.0\_45
%Pour télécharger et installer
%curl -O https://download.elasticsearch.org/logstash/logstash/logstash-1.4.2.tar.gz
%
%tar zxvf logstash-1.4.2.tar.gz
%
%script before-install.sh
%
%sudo cp -r /home/\$USER/Downloads/logstash-1.4.2 /opt/logstash
%
%sudo mkdir /var/log/logstash
%
%script after-install.sh
%
%cd logstash-1.4.2
%
%Création du path
%
%export PATH+=:/opt/logstash
%
%Dautres méthodes d'installation

%Ensuite un simple git clone https://github.com/elastic/logstash.git
%nous permet de récupérer le dépot stable le plus récent.
%Enfin des scripts d'installation sont disponible
%dans logstash/pkg/debian



Sur Debian jessie il n'existe pas de paquet officiel logstash maintenu. Il existe 
en revanche un paquet tiers\fnu{https://download.elastic.co/logstash/logstash/packages/debian/logstash\_1.4.2-1-2c0f5a1\_all.deb}
fourni par l'éditeur du logiciel. Le dit paquet n'est pas de très bonne facture  
puisqu'il nécessite l'ajout de dépendances manuelles\footnote{wget paquet, 
dpkg -i paquet, apt-get install -f} ainsi qu'un rechargement de 
la configuration des services : \emph{systemctl daemon-reload}.

Les dépendances nécessaires sont \emph{jruby} et \emph{openjdk-7-jre}, les mêmes 
que pour elasticsearch.

Une autre manière de réaliser l'installation est d'ajouter les dépots logstash à 
\ipath{/etc/apt/source.list.d/logstash.list.d/logstash.list}

\begin{lstlisting}[style=code,label={lst:ajoutdepotlogstash}]
deb https://packages.elasticsearch.org/logstash/1.4/debian stable main
\end{lstlisting}

et évidemment la clef qui va bien\footnote{permet d'authentifier les paquets téléchargés
(cf:SecureApt)}

\begin{lstlisting}[style=code,label={lst:ajoutclefdepotlogstash}]
wget -qO - https://packages.elasticsearch.org/GPG-KEY-elasticsearch | sudo apt-key add -
\end{lstlisting}

\subsection{Configurations}
Il est d'usage dans une installation \textit{propre} de créer un utilisateur spécifique
à notre utilisation. C'est également le cas dans notre paquet. L'administrateur 
système doit donner à cet utilisateur, nouvellement créer les droits nécessaire 
pour qu'il puisse faire son travail correctement correctement. Dans le cadre de 
l'analyse de log faire de l'utilisateur logstash un membre du groupe \emph{adm}, 
le groupe d'administration de Debian lui permettra par exemple d'avoir accès en 
lecture à la plupart des fichiers de \ipath{/var/log/}.

\subsubsection{Set Capabilities}
Cependant cette façon de faire peut ne pas être suffisante.
Notre utilisation de logstash consiste, entre autre, à centraliser les \gls{logs}. 
Ces derniers sont généralement envoyés par l'intermédiaire de syslog (RFC 5244).
Par défaut syslog utilise le port 514, ce port est inférieur à 1024, et donc \textit{privilégié}.
Aussi seul \emph{root} à le droit d'écouter ces ports. Ajouter notre utilisateur 
logstash au groupe root enlèverait le bénéfice de sécurité obtenu en isolant les 
utilisateurs en fonction de leurs besoins. Nous allons plutôt utiliser les 
\emph{capabilities}\fnu{http://man7.org/linux/man-pages/man7/capabilities.7.html} 
et la commande \emph{setcap}\fnu{https://github.com/elastic/logstash/issues/1587}
\begin{lstlisting}[style=code,label={lst:setcapabilities}]
setcap cap_net_bind_service=+epi /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java
setcap cap_net_bind_service=+epi /usr/lib/jvm/java-1.7.0-openjdk-amd64/jre/bin/java
\end{lstlisting}
qui permettent à un processus (thread en faite) de ne pas se soumettre à certaines 
vérifications de sécurité du noyau.

\textbf{cap\_net\_bind\_service} permet à un utilisateur non privilégié (non root) 
d'écouter sur les ports privilégiés.

Les informations concernants les autres capabilities existants sont disponible dans
la page de manuel correspondante : \emph{man capabilities}.

\textbf{=+epi} signifie que l'on ajoute une \emph{capapbility} à un fichier. Plus 
précisement \textbf{=+} signifie que l'on écrase les droits précédents pour les remplacer
par les nouveaux. \textbf{e, p} et \textbf{i} sont la gradation de droits que l'on peut 
attribuer à un fichier avec les capabilities\fnu{https://www.kernel.org/pub/linux/libs/security/linux-privs/kernel-2.2/capfaq-0.2.txt}. 

\begin{itemize}
    \item \textbf{effective}: indique si la capability est utilisé actuellement
    \item \textbf{permited}: définit quelles capabilities sont autorisé pour un 
    processus donné
    \item \textbf{inherited}: permet de transmettre la capability à un autre programme
\end{itemize}
\textbf{Note}: par défaut, changer le propriétaire d'un fichier de root, à non root enlève
les capabilities associées à ce dernier\footnote{\scriptsize{http://stackoverflow.com/questions/17743062/changing-user-ids-for-assigning-additional-capabilities}}.

Pour vérifier les \textit{capabilities} d'un binaire on utilise la commande 
\emph{getcap}.

\begin{lstlisting}[style=code,label={lst:getcapabilities}]
    getcap /bin/ping
    /bin/ping = cap_net_raw+ep
\end{lstlisting}

Pour les enlever les capabilities il faut utiliser la commande suivante.
\begin{lstlisting}[style=code,label={lst:unsetcapabilities}]
setcap cap_net_bind_service=-epi /usr/lib/jvm/java-1.7.0-openjdk-amd64/jre/bin/java
\end{lstlisting}

Enfin, il est possible, de donner le droit à un utilisateur non root, l'autorisation
de modifier certaines capabilities. Pour ce faire, il faut modifier le fichier \\[1mm]
\ipath{/etc/security/capability.conf}.

%\subsection{Installation de plugins tiers}
%Procédure pour l'installation d'un plugin tiers

\section{Fonctionnement}
\subsection{La base}
Grossièrement Logstash permet traiter et transférer des données, en masse. Nous ne
l'utiliserons essentiellement qu'avec Elasticsearch en utilitaire de sorti. Cependant
et comme le montre la liste des ses abondants plugins d'output, Logstash est capable
de fonctionner avec de nombreux autres logiciels.


\section{Grammaire et conjugaison}
\subsection{Généralités}
Dans cette section nous allons brièvement expliquer le fonctionnement de la syntaxe 
du fichier de configuration de Logstash.\fnu{http ://logstash.net/docs/1.4.2/configuration}

Le ou les fichiers de configuration comportent deux ou trois parties, représentant 
les blocs dont nous avons parlé au préalable. Le bloc \emph{filter} est optionnel
et il est important de noter que, si il est possible de répartir sa configuration
dans plusieurs fichiers, cette dernière sera concaténer, attention aux boucles infinies
dans ce cas là.

\begin{lstlisting}[style=logstash,label={lst:conflogstashminimale},caption={Configuration minimale}]
input {
    stdin{}#ceci est un plugin
}

#filter {
#}#on peut également commenter en fin de ligne

output {
    stdout{}#ceci est un autre plugin
}
\end{lstlisting}

Ici on constate l'utilisation des plugins stdin et stdout, stdin. Comme leur nom 
et leur emplacement dans le fichier de configuration peut le laisser supposer.
Ici Logstash collecte en entrée tout ce qui vient de l'entrée standard, typiquement
le clavier, et l'envoie sur la sortie standard, typiquement, un terminal.
Pour pouvoir recevoir l'output, il est d'ailleurs conseillé d'utiliser, le flag -f
et de ne pas lancer logstash en mode daemon.

Dans ce second exemple, plus complexe, nous allons présenter une utilisation plus
vaste des plugins et la logique sous-jacente à leur utilisation.

\begin{lstlisting}[style=logstash,label={lst:conflogstashiniteloop},caption={Infinite loop}]
#mail.conf
input {
    file {
        path => ["/home/fdupont/testmail"]
    }
}

filter{
    throttle{
        before_count => 2
        after_count => 4
        period => 120
        key => "%{message}"
        add_tag => "contenu"
    }
}

output {
    stdout{ }
    if "contenu" not in [tags]{
        email{
            to => "fdupont@localhost"
            from => "logstash@%{host}"
            subject => "%{message}"
            body => "Ceci est un test sur l'hote %{host}\n avec pour message : %{message}"
        }
    }
}

#shipping.conf
input {
    file {
        path => ["/var/log/secure", "/var/log/messages", "/var/log/*.log","/var/mail/fdupont"]
        exclude => ["*.gz"]
    }
    file {
        path => ["/var/mail/ldidry"]
    }
}


output {
    stdout{ }
    redis {
        host => "100.127.255.1"
        data_type => "list"
        key => "logstash"
    }
}
\end{lstlisting}

Cet exemple de code ne dois pas être utilisé : c'est une boucle infinie.
Il permet en revanche d'expliquer de nombreux points de fonctionnement de la syntaxe
du fichier de configuration de Logstash.
Ce code représente en faite {\bfseries 2 fichiers}, mail.conf et shipping.conf, tout
deux situés dans le répertoire par défaut des fichiers de configuration de Logstash
\ipath{/etc/logstash/conf.d/}. Ils sont lus par ordre alphabétique et concaténés 
(comprendre que les inputs ainsi que les outputs sont fusionnés, il faut donc être
rigoureux dans leur écriture afin de ne pas créer d'effets de bord indésirables).
Une bonne pratique consiste, à utiliser la convention de nommage suivante : \textit{
00-description, 01-description} etc \ldots


Chacun possède un bloc input, output et l'un d'entre eux : filter.
Dans chacun des blocs on trouve un ou plusieurs {\bfseries plugins} comme email, 
file, redis ou d'autres. 
Chacun de ces plugins possède son propre paramétrage, réglable au travers de 
directives, mais avec une syntaxe commune.


\begin{lstlisting}[style=logstash,label={lst:conflogstashsyntaxe1},caption={Syntaxe}]
    directive => int
    directive => "string"
    directive => ["membre", "de", "l'array"]
\end{lstlisting}

La plupart des directives de plugins se comportent ainsi, pas toutes, nous
verrons quelques exemples dans des configurations plus avancées. Dans tout les cas 
est indispensable de référer à la documentation pour toute primo utilisation d'un
plugin.


Comme montré dans le code \ref{lst:conflogstashsyntaxe1} il est également possible 
d'utiliser des structures conditionnelles (les if, else, else if, en faite).
De nombreux opérateurs sont également supportés: ==, !=, <, >, <=, >=, mais aussi
les expressions régulières (syntaxe ruby) =$\sim$, $\sim$! et enfin : in, not in,and,nand,
or,xor et !. 

Dans notre exemple de code \ref{lst:conflogstashiniteloop}, la structure conditionnelle
est utilisé pour faire le trie en utilisant les \emph{tags}.

\subsubsection{Autopsie d'une la boucle infinie}
La configuration \ref{lst:conflogstashiniteloop}, qui ne fonctionne pas
correctement n'a pas été mise là par hasard. Cette erreur, permet de bien comprendre 
le fonctionnement des fichiers de configuration de Logstash.

Rappels : Il y a dans cette configuration, 2 fichiers de configuration. Les fichiers,
sont concaténés au lancement de Logstash de telle sorte que virtuellement cela donnerait 
un résultat similaire à :


\begin{lstlisting}[style=logstash,label={lst:conflogstashiniteloop2},caption={Infinite loop concaténé}]
#mail.conf
input {
    file {
        path => ["/home/fdupont/testmail"]
    }
    file {
        path => ["/var/log/secure", "/var/log/messages", "/var/log/*.log","/var/mail/fdupont"]
        exclude => ["*.gz"]
    }
    file {
        path => ["/var/mail/ldidry"]
    }
}

filter{
    throttle{
        before_count => 2
        after_count => 4
        period => 120
        key => "%{message}"
        add_tag => "contenu"
    }
}

output {
    stdout{ }
    if "contenu" not in [tags]{
        email{
            to => "fdupont@localhost"
            from => "logstash@%{host}"
            subject => "%{message}"
            body => "Ceci est un test sur l'hote %{host}\n avec pour message : %{message}"
        }
    }
    redis {
        host => "100.127.255.1"
        data_type => "list"
        key => "logstash"
    }
}
\end{lstlisting}

Ici le problème semble plus évident l'output et l'input sont "liés". Des messages
peuvent être détectés et envoyés par mail à l'adresse \ipath{fdupont@localhost} (soit
l'équivalent de \ipath{/var/mail/fdupont}). Ce fichier est également écouté, ainsi que la 
plupart de fichiers de logs, voilà la source des boucles infinies, assez facilement
reproductible si l'on n'est pas suffisamment rigoureux, et surtout si l'on travail 
sur plusieurs fichiers à la fois.

L'autre erreur majeur de ce fichier se situe à la ligne 27. Si le terme contenu 
n'est pas présent dans "tags" alors on envoie un mail. Le fonctionnement est l'inverse 
de celui suggérer par throttle. Ici un mail est envoyé dès qu'un événement se produit
dans un fichier de log. Ce mail envoyé dans /var/mail/fdupont sera renvoyé dans cette
même adresse, le contenu de l'événement se modifiera en permanence puisque le message
sera encapsulé dans son prédécesseur \ldots

\subsection{Expressions régulières et patterns}
Les expressions régulières utilisées par Logstash dans le plugin grok utilisent le 
moteur Oniguruma dont les spécifications sont disponibles à cette 
\href{http://www.geocities.jp/kosako3/oniguruma/doc/RE.txt}{adresse}\footnote{http://www.geocities.jp/kosako3/oniguruma/doc/RE.txt, 
si des symboles \textbf{ \textyen} apparaissent vous avez probablement un problème d'UTF8 sur 
votre navigateur, ils correspondent à des \textbf{ \textbackslash}}.
Ruby n'utilise plus Oniguruma depuis la version 2.0 mais son fork Onigmo\footnote{
dixit Wikipédia https://en.wikipedia.org/wiki/Oniguruma}

\subsubsection{Les expressions régulières de Grok}
Ce moteur permet des manipulations avancées d'expressions régulières, ce n'est pas 
l'objet de ce projet de les présenter. Nous nous contenterons simplement d'utiliser
des syntaxes assez classiques d'expressions régulières à l'exception des named groups. 
Qui permettent avantageusement de ne pas utiliser les patterns, ou plutôt d'en créer
de nouveaux sans modifier les fichiers de Logstash.
{\footnotesize(Grok est le plugin dont on se servira le plus avec Logstash c'est 
pour cela que nous prenons le temps de présenter son système d'expression régulière)}


\begin{lstlisting}[style=logstash,label={lst:grokregex1},caption={Named group}]
(?<nom_du_champ>Pattern) 
(?<username> [a-zA-Z0-9._-]+)
\end{lstlisting}

Grok créera rangera automatiquement une chaine de caractère satisfaisant la contrainte 
\ipath{/[a-zA-Z0-9.\_-]+/}  dans un champ  username. 
Ce champ pourra être réutiliser ultérieurement par Logstash ou même Elasticsearch.


\subsubsection{Les patterns}
Logstash mets en place un système très utile et très facile à utiliser de patterns 
(motifs), ces patterns correspondent à des mots clefs représentant des expressions 
régulières ou bien des concaténations d'expressions régulières ou de patterns.

La compréhension des patterns est simple et presque instantané si l'on connait les
expressions régulières.
\begin{lstlisting}[style=logstash,label={lst:patternsexplication1},caption={Exemple de définition et d'utilisation de Patterns}]
CISCOMAC (?:(?:[A-Fa-f0-9]{4}\.){2}[A-Fa-f0-9]{4})
WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2})
COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2})

MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC})
\end{lstlisting}

Grok peut également utiliser ces patterns mais leur fonctionnement est général dans
Logstash.
On comprends bien dans le code précédent le fonctionnement des patterns : qui est
très similaire à celui des \textit{named groups} : définition d'un nom, expression
régulière associé. On les utilise en invoquant leur nom entouré par \%{} 
Il sont utilisable ensemble comme dans l'exemple ci-dessus avec les adresses MAC,
ou (beaucoup) plus bas dans l'explication du fonctionnement de l'architecture.


\subsection{Les flags}
Les \emph{flags} sont les noms donnés aux paramètres que l'on peut donner au binaire
de Logstash.

\begin{itemize}
    \item -f : file, désigne le fichier de configuration à utiliser
    \item -e : permet d'utiliser une chaine de caractères (depuis la console) pour
    pour configurer Logstash, à utiliser pour faire des tests de configuration simple.
    \item -w : filterworkers, comme expliqué plus haut, permet d'affecter plusieurs
    threads à la gestion des filtres. (par défaut 1)
    \item - -configtest : associé à -f \ipath{path/to/conffile} vérifie la syntaxe 
    du fichier de configuration.
\end{itemize}

Par défaut Logstash utilisera les fichiers de configuration présents dans \\ \ipath{
/etc/logstash/conf.d/}, ils seront ouverts par ordre alphabétique.




Les fichiers de confs et leurs fonctionnement + interaction entre plugins et etc...

\section{Utilisation}
On peut utiliser Logstash de plusieurs façons, de manière plus ou moins complexe 
en fonction de nos besoins et de notre infrastructure.
La configuration la plus simple consiste à 


\section{Mon serveur central}



\section{Monter à l'échelle}




