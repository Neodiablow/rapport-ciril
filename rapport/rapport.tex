\documentclass[a4paper,10pt,one side,titlepage]{report}


%en francais
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}


\usepackage{listings}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{eurosym}
\usepackage{url}
\usepackage{pdfpages}
\usepackage{wrapfig}
\usepackage[hidelinks]{hyperref}
\usepackage[acronym]{glossaries}
\usepackage{float}
%\usepackage[top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm]{geometry}
%\hypersetup{pdfborder=0}

\graphicspath{ {../images/} {/home/neodiablow/git/pt2015-web/rapports/images/} } % dossier img

\lstdefinestyle{python}
{
language=python,
numbers=left,
numberstyle=\tiny,
backgroundcolor=\color{yellow!20},
keywordstyle=\color{blue!50!green!50}\bfseries,
commentstyle=\color{black},
stringstyle=\color{red},
showstringspaces=false,
basicstyle=\small\color{blue},
captionpos=b,
tabsize=2,
frame=tb,
breaklines=true
columns=fullflexible,
linewidth=0.9\linewidth,
xleftmargin=0.1\linewidth
}

\lstdefinestyle{code}{
language=bash,
basicstyle=\small\sffamily,
numbers=left,
numberstyle=\tiny,
numbersep=3pt,
frame=tb,
breaklines=true
columns=fullflexible,
backgroundcolor=\color{yellow!20},
linewidth=0.9\linewidth,
xleftmargin=0.1\linewidth
}


%GABRIEL
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}


%%% header & footer
% \leftmark : afficher nom section
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\fancyhead[C]{Haute Disponibilité pour le Web} 
\fancyhead[L]{}
\fancyhead[R]{}%\includegraphics[width=60px]{openstack-logo.png}}

\renewcommand{\footrulewidth}{1pt}
\fancyfoot[C]{Page \thepage} 
\fancyfoot[L]{IUT CHARLEMAGNE}
\fancyfoot[R]{Licence Pro ASRALL}



%Titre et Auteurs
\title{Architecture pour l'hébergement web à fort trafic}
\author{Auteurs : \textit{Dupont Francois}\\\\Tuteur : \textit{Vincent Delove}}
%\date{Lundi 23 Mars 2015}


\input{./glossaire.tex}

\makeglossaries

\begin{document}

%Insertion du logo de l'iut et de l'univ Lorraine
%\begin{figure}
%\centering
%\includegraphics[width=0.5\textwidth]{Logo-IUT-UL.jpg}
%
%\end{figure}
%
%\maketitle
%
%\begin{figure}[h]
%    \centering
%    
%   % \vspace{5cm}
%    \includegraphics[scale=0.5]{haproxy.png}
%    %\hspace*{10mm}
%    \includegraphics[width=0.5\textwidth]{nginx.png}
%    \\[0.2cm]
%    \includegraphics[width=62px]{percona.png}
%    \hspace*{25mm}
%    \includegraphics[scale=0.5]{debian.png}
%\end{figure}


\input{./title.tex}



%Page remerciments
\emph{\Large Remerciements}
\\[2cm]
Nous remercions Patrick Nourissier, notre tuteur, pour sa disponibilité, son 
suivi, son aide et ses encouragements. 
\\[1cm]
Nous remercions openssh de nous permettre d'optimiser nos horaires de travail.

%\begin{abstract}
%Dans une entreprise, tous les services ne nécessitent pas une disponibilité ou accessibilité constante, cependant, certains services sont vitaux et il n'est pas envisageable de les arrêter sans occasionner des pertes conséquentes pour l'entreprise (un site e-commerce d'envergure mondiale inaccessible). 
%
%Notre projet a pour objectif d'étudier et de proposer des solutions (une pile logicielle) permettant de répondre à ces besoins impitoyables de disponibilité, dans le cas de sites web engendrant un fort trafic.
%\end{abstract}
%\newpage

%Page table des matières
\setcounter{tocdepth}{1}
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Introduction
\part{Introduction}
%Cette partie va nous amener à présenter le projet et ses objectifs ainsi qu'expliquer 
%des notions générales et clefs pour comprendre les infrastructures 
%de haute disponibilité et les architectures complexes.
\chapter{Gestion de projet}
Tout d'abord, voici une brève présentation du projet et de nos objectifs.
\section{Problématique}
Étudier la mise en place d'une architecture permettant l'hébergement de sites 
internet à fort trafic. S'il reste du temps, étudier le tuning fin et les règles à 
mettre en place pour renforcer la sécurité.

Ce projet devra être réalisé sur un délai de deux mois.

\section{Nos objectifs}
Dans ce projet, nous avions pour objectif d'étudier, comprendre, tester et réaliser 
une architecture haute disponibilité orientée pour des besoins web.

En concertation avec notre tuteur de projet, nous avons décidé d'expérimenter plusieurs
technologies et de choisir celles qui nous paraissaient les meilleures. 

Pour réaliser nos choix, nous nous sommes basés sur nos tests, les conseils de notre
tuteur et la littérature disponible sur le sujet.

Dans la mesure du possible, nous avons essayé de réaliser nos installations sur les
futurs standards : les versions testing/dev des logiciels.

\chapter{Définitions}
Dans cette partie, nous allons essayer d'expliquer clairement les notions que nous
allons aborder dans le reste du rapport. Cette partie fera également office de 
description des alternatives à la solution que nous proposons, nous en profiterons
également pour faire le bilan de l'état de l'art actuel dans l'industrie.
\section{La disponibilité}
Ce mot n'est pas présent dans l'intitulé de notre sujet, il est pourtant sous-entendu
et essentiel. Pouvoir gérer beaucoup de trafic (tenir la charge) ne doit pas être 
ponctuel. Aujourd'hui, un service doit pouvoir être disponible en permanence ou à 
la demande, d'où la nécessité de définir la \emph{disponibilité}. 

La disponibilité d'un équipement ou d'un système est une mesure que l'on obtient
en divisant la durée durant laquelle l'équipement est opérationnel et la durée
pendant laquelle on aurait souhaité qu'il le soit.
Typiquement, on calcule la disponibilité en divisant la durée effective de fonctionnement
par la durée totale.

Cependant, en fonction du système considéré, toutes les indisponibilités ne sont pas
critiques. On peut penser aux arrêts planifiés, qui auront été anticipés et convenus 
entre client et fournisseur de service et dont l'impact est souvent très faible.
Ou bien les arrêts se produisant pendant les périodes de faible affluence ( par exemple 
entre 2h et 4h du matin).

On commence à considérer qu'un système est très disponible à partir de 99,9\% de disponibilité annuelle.
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Disponibilité en \%&    Indisponibilité annuelle& Indisponibilité mensuelle\\
        \hline
        95\%&       18,25 jours&    36 heures\\
        \hline
        99,0\%& 3,65 jours& 7,20 heures\\
        \hline
        99,9\%& 8,76 heures&    43,2 minutes\\
        \hline
        99,99\%& 52,56 minutes& 4,32 minutes\\
        \hline
        99,999\%& 5,26 minutes& 25,9 secondes\\
        \hline
    \end{tabular}
    \caption{Table d'équivalence de disponibilité}
    
    \label{tab:disponibilite}
\end{table}
\newpage
La formule généralement utilisé pour définir la disponibilité est la suivante :
\[
MTBF=MTTR+MTTF
\]
\[
disponibilité = \frac{MTTF}{MTBF}
\]
MTBF pour Mean Time Before Failure, temps moyen avant la panne\\
MTTR pour Mean Time To Repair, temps moyen pour réparer une panne\\
MTTF pour Mean Time To Failure, temps moyen jusqu'à la panne (aussi appelé 
fonctionnement normal)


\begin{figure}[h]
    \centering
\includegraphics[scale=0.8]{dispo.png}
    \caption{Représentation disponibilité}
    \label{fig:repdispo}
\end{figure}

Où 0 représente un service indisponible, et 1 le service accessible.

\section{Qu'est-ce que la très haute disponibilité?}
La \emph{haute disponibilité} est le principe qui consiste à rendre une 
application, un site web ou un service le plus disponible possible (en permanence 
si possible).\\

Cela implique que le service web puisse répondre et se comporter conformément à 
ce qui est attendu dans un temps convenable, même si le trafic est important.\\ 

On considère par exemple qu'un site web ne doit jamais mettre plus de 3 secondes 
à répondre à une requête. Évidemment, le ressenti pour l'utilisateur sera 
grandement dépendant de la qualité de sa connexion à un internet, mais il faut 
rendre notre infrastructure suffisamment véloce pour que la latence induite 
devienne marginale. \\

En fonction des moyens de l'entreprise\footnote{la disponibilité est pratiquement 
fonction des moyens investis dedans} et de l'aspect critique ou non d'un service 
et de la qualité de service que l'on souhaite délivrer\footnote{Il est de 
notoriété publique que \emph{Free} ne souhaite pas servir \emph{youtube.com} de 
façon convenable, pour des raisons politiques et économiques}, il est évidemment 
possible de faire varier la tolérance de l'indisponibilité. \\

Pour réaliser cela, une infrastructure haute disponibilité doit être dimensionnée, 
pour pouvoir encaisser un trafic bien supérieur à son trafic nominal\footnote{Dans 
notre rapport il ne sera pas question de résister à un \gls{DDOS} sérieux, juste 
à un trafic inhabituellement élevé}.\\ %Il faudra donc estimer le trafic attendu en fonction du nombre de visiteurs prévus par jour/heures et effectuer des tests en conséquence.\\ 

L'infrastructure doit également être conçue pour être le moins indisponible possible, 
cela sous-entend ajouter de la redondance partout où cela est nécessaire. Créer 
une infrastructure que l'on puisse mettre à jour sans coupure de service (il n'est 
même pas envisageable de pouvoir penser échapper aux mises à jour\footnote{il 
semble que de nombreuses banques ne possèdent pas vraiment d'infrastructure haute 
disponibilité}), répartir la charge autant que possible, prévoir la possibilité de 
passer à l'échelle\footnote{\gls{scalabiliser}}...\\

Une infrastructure haute disponibilité nécessite des moyens matériels\footnote{abordé de 
manière très parcellaire dans ce rapport, la description exhaustive d'une 
\emph{infrastructure matérielle} dépasse le cadre de notre étude}
importants, qui ne sont en pratique possible à mettre en œuvre que chez un hébergeur.\\ 
Au niveau logiciel la mise en place doit être planifiée, car les technologies 
utilisées sont pointues et complexes à mettre en œuvre. Leurs configurations sont 
très liées aux machines sur lesquels elles se trouvent, cela nécessite une 
automatisation de l'installation pour gagner du temps et éviter les erreurs.\\

Dans ce projet nous n'avons pas pour objectif de monter une infrastructure capable 
de résister à une attaque importante de type \gls{DDOS}. Nous, nous proposerons des 
pistes pour en réduire la portée et l'efficacité de ce genre d'attaque notamment 
avec un \gls{firewall}, mais pas comment arrêter les attaques les plus sérieuses. 
Ce qui est à notre connaissance impossible\footnote{blackholing \gls{BGP} en dernier recours}.

\section{Les architectures en couches}
\input{archicouche.tex}

\subsection{SPOF}
SPOF est un terme anglais Single Point Of Failure signifiant point unique de défaillance.
C'est un terme courant servant à qualifier une faiblesse dans l'architecture.
L'objectif est toujours d'éviter d'avoir un SPOF, c'est malheureusement rarement 
possible, et extrêmement coûteux.

\subsubsection{La remonté du SPOF}
Il est possible d'éliminer un point de défaillance, mais souvent, le problème est le même sur la couche supérieur. Un exemple pour mieux comprendre, pour éviter une indisponibilité je décide de prévenir la panne de disque dur. 
Je mets en place un système de RAID1 qui préservera l'intégrité de mes données et 
permettra une continuité de service. 

Cependant ce système se révèlera inopérant si un problème électrique survient, on
peut imaginer que mon alimentation (pourtant gold) décide subitement de ne plus
fonctionner. On peut anticiper le problème en mettant en place une alimentation 
redondante. Dans ce cas ci nos précautions actuelles ne pourraient en revanche 
rien contre une défaillance de la distribution électrique (un arbre qui tombe sur
une ligne électrique). Ce problème pourrait être réglé par la mise en place d'un 
onduleur et d'un générateur (diesel par exemple). 

On pourrait évidemment citer l'exemple de la pelleteuse qui arrache notre fibre, etc..
la liste est sans fin. Mais on voit bien que plus on remonte la chaîne moins les 
défaillances sont de notre ressort, certaines grandes entreprises avec des moyens 
quasiment illimités ont pris les devant en construisant leur propres centrales 
électriques (google par exemple). D'autres problèmes rentrent également en ligne 
de compte les peerings, une requête \gls{BGP} malencontreuse, une catastrophe naturelle etc..

La chasse au SPOF a de quoi rendre paranoïaque. 

À noter que dans notre architecture plusieurs points peuvent être défaillantes comme 
l'alimentation électrique ou bien notre \gls{load balancer}/reverse proxy, ou même 
notre DNS.




\chapter{Outils}

%\section{Debian}
%GNU/Linux Debian ce choix était un souhait de notre tuteur, c'est une distribution
%robuste que nous utilisons quotidiennement dans notre formation. Aprécié en entreprise
%du fait de son excellence technique meme si on lui préfère souvent les RHEL-like 
%du fait de leur support et ou proximité avec RHEL qui dispose d'un support technique.

\section{La stack logicielle}
Une stack logicielle est un terme employé pour désigner un groupe de logiciels 
qui interagissent ensemble afin de réaliser un objectif. Cet ensemble de logiciels 
acquière généralement le \textit{titre} de stack lorsque ce groupe devient un 
standard utilisé de façon normalisé ou au moins récurrente dans l'industrie.

On peut par exemple penser à la célèbre stack LAMP : Linux Apache Mysql Php.

Cette dernière, bien qu'éprouvée et très stable, présente quelques problèmes de 
performances nous lui avons préféré une stack LHANPP : Linux HAProxy Nginx Percona PHP
(Percona $ \approx $ Mysql).

Il est à noter que, de manière générale, dans une stack, chaque composant ne réalise 
qu'une seule tâche spécifique, bien que le dit composant soit généralement capable de
réaliser d'autres cas d'utilisation. Il semble que dans ce domaine la philosophie 
UNIX soit toujours observée avec une certaine discipline.

\subsection{Load balancing}
L'une des techniques de base pour permettre de la haute disponibilité est d'avoir
plusieurs serveurs et de répartir la charge sur ces machines. L'idéal étant évidement
d'avoir un nombre de machines suffisant pour permettre de tenir la charge, malgré
l'indisponibilité de certaines.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{loadbalancing.jpg}
    \label{fig:loadbalancing}
    \caption{Exemple de représentation d'un load balancing}
\end{figure}


\subsection{Reverse Proxy}
Un serveur proxy sert généralement à un ou plusieurs utilisateurs à aller sur internet,
le reverse proxy permet l'inverse c'est à dire aux clients/utilisateurs venant par 
exemple d'internet d'accéder à un service/contenu local.

\subsection{Cache}
Le principe du cache est d'enregistrer en mémoire une requête récurrente afin de 
pouvoir la servir lors d'une demande ultérieure sans avoir à recalculer cette requête
ou demande. Le cache peut physiquement, s'enregistrer sur le disque dur ou bien 
s'enregistrer sur la mémoire RAM. On choisira la meilleur solution en fonction de
nos contraintes techniques et de nos besoins.

Le cache peut se situer à plusieurs endroits, il est possible de faire un cache 
HTTP en cas de demandes nombreuses sur une page, on peut également faire du cache
de requêtes SQL ou de code php compilé.

\section{Monitoring}
Le monitoring est un anglicisme qui désigne la surveillance des serveurs ou des 
des services avec des outils dédiés. Le monitoring sert à s'assurer de la bonne 
santé de son parc et permet de réagir vite à une panne et même parfois d'être pro actif.

On peut également utiliser ces outils à des fins statistiques, nous en présenterons
quelques uns dans les chapitres à venir.

\section{Complexification de la stack}
Nous avons dit ne pas vouloir utiliser la stack LAMP pour
cause de manque de performances (et parce que ce n'était pas notre sujet). Mais un
des problèmes de ne pas utiliser une stack standard est qu'elle n'est pas aussi 
éprouvée, qu'il y a moins de support et donc généralement plus de problèmes.

LAMP est également ce qu'on peut appeler une stack simple, un système d'exploitation,
un serveur web, une base de données, un langage interprété.

Plus on ajoute d'outils et donc de couches à notre stack plus les choses peuvent se compliquer. Pour avoir quelque chose de maintenable dans le temps il est important
de garder un système relativement simple et si possible dont l'entièreté est
compréhensible par plusieurs personnes (documentation !).

Mais comme expliqué précédemment notre objectif est également d'améliorer les 
performances. La difficulté dans ce genre d'architecture est de maintenir l'équilibre 
entre une stack suffisamment performante et \textit{bleeding edge}, et une stack 
stable et abondamment utilisée.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\part{Étude}
\chapter{LXC}
\input{./lxc.tex}

\chapter{HA-Proxy}
\input{./haproxy.tex}

\chapter{Collectd}
\input{./collectd.tex}

\chapter{Munnin}
\input{./munin.tex}

\chapter{Apache2}
Cette partie ne sera pas très renseigné ni très techniques, Apache est un logiciel connu
et ses différences de performances avec Nginx sont traités la partie Nginx.
\section{Un peu d'histoire}
Le logiciel libre Apache HTTP Server (Apache) est un serveur HTTP créé et maintenu au sein de la fondation Apache. C'est le serveur HTTP le plus populaire du World Wide Web. Il est distribué selon les termes de la licence Apache.\\
Apache est apparu en avril 1995. Au début, il s'agissait d'une collection de correctifs et d'additions au serveur NCSA HTTPd 1.3, qui était dans le domaine public et le serveur HTTP alors le plus répandu. De cette origine, de nombreuses personnes affirment que le nom Apache vient de a patchy server, soit « un serveur rafistolé ». Par la suite, Apache a été complètement réécrit pour la version 2.\\
Au début, Apache était la seule alternative sérieuse et libre au serveur HTTP de Netscape.\\
\section{Aspects techniques}
Apache est conçu pour prendre en charge de nombreux modules lui donnant des fonctionnalités supplémentaires : interprétation du langage Perl, PHP, Python et Ruby, serveur proxy, Common Gateway Interface, Server Side Includes, réécriture d'URL, négociation de contenu, protocoles de communication additionnels, etc. Néanmoins, il est à noter que l'existence de nombreux modules Apache complexifie la configuration du serveur web. En effet, les bonnes pratiques recommandent de ne charger que les modules utiles : de nombreuses failles de sécurité affectant uniquement les modules d'Apache sont régulièrement découvertes.\\
Un des points fort d'Apache est sa possibilité de configuration, en effet cela en fait une fonctionnalité phare. Le principe repose sur une hiérarchie de fichiers de configuration, qui peuvent être gérés indépendamment.

\chapter{Nginx}
\input{./nginx.tex}

\chapter{Joomla}
\input{./joomla.tex}

\chapter{Mysql et Percona}
\input{./mysqlpercona.tex}

\chapter{Varnish}
\input{./varnish.tex}

%\chapter{DRBD}
%\input{./drbd.tex}
%
%
\chapter{Autres}
\section{Sécurtié}
\input{./securite.tex}

\section{Tuning}
\input{./tuning.tex}

\section{DNS et IP}
\input{./dns.tex}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\part{Notre architecture haute disponibilité}
\chapter{Nos choix}
Dans cette partie nous allons exposer les choix logiciels que nous avons effectués
pour réaliser ce qui nous semblait être la meilleure infrastructure haute disponibilité
orientée web possible. Dans le temps imparti et avec les contraintes matérielles de
la salle (nous avons un peu triché en apportant un switch gigabit non manageable
personnel).
\section{Notre architecture}
Très tôt et sur conseil de notre tuteur nous nous sommes orienté sur une architecture 
deux tiers (en séparant la partie logique de l'application de la partie données). 
À cette architecture nous comptions rajouter un \gls{load balancer} de tête et un 
DRBD en \gls{failover} par serveur de base de données(\ref{fig:archidebase}).

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.3]{archi_de-base.png}
    \caption{Architecture de base}
    \label{fig:archidebase}
\end{figure}

Cette architecture avait l'avantage d'être assez complexe, potentiellement scalable
et sûr pour les données. Le \gls{failover} nous permettant théoriquement de ne pas 
souffrir d'interruption de service, mis à part en cas de défaillance de notre serveur
HAProxy. Pour réduire ce risque nous avons choisi dès le départ d'installer HAProxy
sur un containeur LXC. 

L'avantage du containeur est qu'il est facilement et rapidement clonable. Ainsi il
est très rapide dans le cas d'une maintenance programmée de lancer ce second containeur, 
changer les IP, effectuer la maintenance (typiquement une mise à jour ou bien un 
changement de configuration) et enfin de refaire les mêmes opérations dans l'autre
sens. Évidemment cela ne prévient pas la panne matérielle.

Prévenir la panne matérielle sur le \gls{load balancer} était pour nous extrêmement 
compliqué, tout d'abord parce que nous manquons de machines, ensuite parce que nous 
manquons d'IP, de câbles réseau, de prises réseau, de prises électriques et enfin 
parce que comme expliqué plus haut les systèmes à mettre en place pour parer à ce 
genre d'éventualité sont complexes. Mais la raison principale est le manque de moyen.


Suite à des soucis rencontrés dans la mise en place de HAProxy en mode TCP nous avons
choisi de nous orienter sur une autre architecture, finalement pas si différente.
On remarquera la disparition des machines DRBD, ce choix a été effectué  puisque nous
n'avons pas suffisamment eu le temps de nous renseigner sur ce logiciel pour 
envisager sa mise en place.

Notre architecture finale (\ref{fig:archiactuelle}) est donc toujours une architecture deux tiers mais avec
cette fois-ci un cluster de base de donnée avec trois machines et non pas deux et la disparition
des machines DRBD.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.3]{archi-actuelle.png}
    \caption{Notre architecture}
    \label{fig:archiactuelle}
\end{figure}

Percona remplace avantageusement DRBD en terme de facilité de mise en place et de
maintien de l'intégrité des données. En revanche dans la configuration actuelle les
performances ne sont pas très intéressantes.



\section{Installation des machines}
Les OS installés ont été des GNU/Linux Debian testing (dans un premier temps).

Le choix de testing a été fait car nous souhaitions que dans la mesure du possible que
nos recherches soient toujours valides dans un futur proche. La testing actuelle 
étant en \textit{Freeze} à priori tout ce que nous avons mis en place, sera reproductible
pour de nombreuses années.

Pour réaliser l'installation nous avons simplement suivi l'installation d'une debian
netinstall\footnote{La plus légère} minimale (juste openssh en plus du \textit{bare debian}) 
en prenant bien garde de remplacer le proxy par défaut par celui de la salle.

La modification s'est faite en mode interactif, mais ces informations sont écrites
dans le /etc/apt/apt.conf

\begin{lstlisting}[style=code]
Acquire::http::Proxy "www-cache.iutnc.univ-lorraine.fr:3128";
\end{lstlisting}

Après plusieurs essais ayant échoués sur une machine (upgrade de stable à testing).

Nous avons créé un script bash d'installation \ref{lst:bashinstall} qui nous a permis 
d'automatiser l'installation d'un environnement de travail fonctionnel et agréable. 
Ce script a été déployé à distance, sans encombre (oui, on peut scier la branche 
sur laquelle on est assis sans tomber).

Il est à noter que trois machines ont été ultérieurement réinstallées avec Wheezy
car pour l'instant Percona n'est utilisable que sur cette version.

\subsection{Difficultés}
Outre les difficultés d'organisation et de proxy, nous avons dû faire avec le 
le matériel défaillant ainsi que le DHCP sur lequel nous n'avions pas la main, (et dont
la limite d'ip fixe a été dépassée) et le miroir debian de la salle très capricieux.

Les câbles ethernet cassés nous ont permis de nous assurer de la solidité de notre 
infrastrucutre. 

Par manque de temps et à cause de l'abscence du preseed originalement prévu nous 
nous sommes rabattu sur une méthode très classique d'installation, que nous 
maitrisions bien, la clef USB. Ce n'est évidemment pas la méthode que l'on recommande
pour l'installation d'un grand nombre de machines, mais pour 7 la perte de temps 
était acceptable.

\section{HA Proxy (et LXC)}
\input{installhaproxy.tex}

\newpage
\section{Nginx}
\begin{figure}[H]
    \centering
\includegraphics[scale=1]{../images/nginx.png} 
    \label{fig:nginxintro}
\end{figure}

\subsection{Etapes d'installation}
Voici les étapes d'installation pour Nginx pour les distributions Debian et Ubuntu.\\
Tout d'abord il faut ajouter les sources pour avoir les dernières versions stables, pour cela il suffit de faire:
\begin{enumerate}
\item sudo add-apt-repository -y ppa:nginx/stable
\item sudo apt-get update
\end{enumerate}
Suite à la commande \textbf{apt-get update} il suffit simplement de lancer l'installation:
\begin{itemize}
\item sudo apt-get install -y nginx
\end{itemize}
Ensuite, il faut aller voir sur un navigateur (localhost bien entendu) pour voir si Nginx est disponible ou non (un peu comme Apache).
\subsection{Configuration de notre serveur Web}
Tout d'abord, il est important de donner les répertoires de configuration pour Nginx qui sont dans \textbf{/etc/nginx}
\begin{itemize}
\item /etc/nginx/conf.d
\item /etc/nginx/sites-available
\item /etc/nginx/sites-enabled
\item /etc/nginx/nginx.conf
\end{itemize}
Et puis comme Apache nous avons les dossiers "sites-available" et "sites-enabled" pour ainsi configurer les sites en général.
De plus, si votre site est seulement de type static vous pouvez ne configurer uniquement que le chemin de votre site à prendre en compte. Mais attention, si notre site/application est dynamique il faut activer le mode \textbf{PHP}!\\
\subsection{Installation de Joomla}
Pour commencer l'installation de Joomla il faut tout d'abord vérifer que celui-ci est accéssible via notre navigateur(bien entendu la configuration se fait dans le dossier \textbf{site-enable} de Nginx).\\
Après cela nous pouvons commencer l'installation, pour se faire rien de plus simple il suffit de suivre les instruction de la première partie:\\
\begin{figure}[H]
    \centering
\includegraphics[scale=0.5]{../images/install-joomla.png} 
    \caption{Etape 1}
    \label{fig:Etape1install}
\end{figure}

Ensuite pour la seconde partie nous allons nous baser sur notre configuration:\\
\begin{figure}[H]
    \centering
\includegraphics[scale=0.5]{../images/BDD-joomla.png}
     \caption{Etape 2}
    \label{fig:Etape2install}
\end{figure}
Pour le \textbf{type de base de données} nous utilisons : \textbf{MySQLi}\\
Ensuite pour le \textbf{nom du serveur} nous utilisons un serveur local qui a pour IP \textbf{192.168.1.6}
%\begin{lstlisting}[style=code]
%\end{lstlisting}
Pour les trois parties qui vont suivre il va falloir ajouter via Mysql, un utilisateur, un mot de passe et pour finir une base de données. Après avoir crée tout ceci et avoir renseigné les champs de la section base de données, nous pouvons finir l'installation de joomla!
\subsection{Points importants}
Lors de la création de la base de données, il faut bien entendu faire attention aux droits de connexions à la base pour les serveurs Web. En effet, il est important de leur donner les privilèges nécessaire pour l'installation et l'utilisation globale.
Par exemple comme ceci 
\begin{lstlisting}[style=code]
CREATE USER 'root'@'192.168.1.28' IDENTIFIED BY 'pomme';
\end{lstlisting}
Puis maintenant les droits : 
\begin{lstlisting}[style=code]
GRANT ALL PRIVILEGES ON joomla.* TO 'root'@'192.168.1.28' WITH GRANT OPTION;
\end{lstlisting}
Grâce aux configurations précédentes lors de votre installation de Joomla, celui-ci sera donc capable de se connecter au serveur de base de données local.


\section{Percona}

\subsection{Etapes d'installation de Percona XtraDB Cluster}
Dans ce chapitre, nous allons voir les étapes pour l'installation du fork de MySQL et qui va nous servir à créer notre cluster ainsi que notre réplication de bases de données.
Quelques points avant l'installation de Percona XtraDB Cluster, Percona prend en support les architectures suivantes:
\begin{itemize}
\item x86-64 (amd64)
\item x86
\end{itemize}
Ce logiciel est compatible avec les systèmes suivants :
Debian :
\begin{itemize}
\item 6.0 squeeze
\item 7.0 wheezy
\end{itemize}
Ubuntu :
\begin{itemize}
\item 10.04 LTS lucid
\item 12.04LTS precise
\item 13.10 saucy
\item 14.04 LTS trusty
\end{itemize}

Pour commencer l'installation, il faut en premier lieu ajouter les clés, pour cela il faut faire :
\begin{itemize}
\item apt-key adv --keyserver keys.gnupg.net --recv-keys 1C4CBDCDCD2EFD2A
\end{itemize}
Ou bien alors ajouter les sources à la main dans \textbf{/etc/apt/sources.list}\\
Et si cela ne fonctionne toujours pas sous Debian, il y existe une dernière solution; télécharger le ficher \textbf{percona-release\_0.1-3.wheezy\_all.deb} et 
ensuite l'exécuter avec la commande \textbf{dpkg -i}
\begin{itemize}
\item deb http://repo.percona.com/apt VERSION main
\item deb-src http://repo.percona.com/apt VERSION main
\end{itemize}
Ensuite il faut faire la commande suivante :
\begin{itemize}
\item apt-get update
\end{itemize}
Suite à ces commandes nous pouvons passer à l'installation de Percona XtraDB 
Cluster, pour se faire rien de plus simple :
\begin{itemize}
\item sudo apt-get install percona-xtradb-cluster-55
\end{itemize}
Pour Ubuntu 14.04 ce sera :
\begin{itemize}
\item sudo apt-get install percona-xtradb-cluster-55 percona-xtradb-cluster-galera-2.x
\end{itemize}

\subsection{La configuration du cluster}
Suite à l'installation de Percona XtraDB Cluster il faut réaliser la configuration 
des noeuds, pour se faire il faut configurer chaque noeud un à un.

Voici les noeuds de notre configuration:

\begin{figure}[h]
    \centering
\includegraphics[scale=1]{liste-MySQL.PNG} 
    \caption{Machines utilisées pour notre cluster}
    \label{fig:machinecluster}
\end{figure}

Pour la configuration des noeuds il faut modifier le fichier suivant :
\begin{itemize}
\item \textbf{/etc/mysql/my.cnf}
\end{itemize}

Avec votre éditeur de texte préféré, modifier \textbf{my.cnf}.

Pour commencer voici un exemple de configuration pour notre noeud N\degre1 :
\begin{figure}[h]
    \centering
\includegraphics[scale=0.4]{../images/noeud1-perco.png}    
    \caption{Configuration du noeud 1}
    \label{fig:ConfigNoeud1}
\end{figure}
Après avoir modifié \textbf{my.cnf} il faut redémarrer le service avec la commande suivante : \textbf{/etc/init.d/mysql bootstrap-pxc}
en plus de redémarrer le service, cette commande initialise le cluster.
Ensuite nous allons vérifier le statut du cluster dans MySQL avec la commande suivante:
\textbf{show status like 'wsrep\%';} .
Nous devons avoir un résultat comme celui-ci:
\begin{figure}[H]
    \centering
 \includegraphics[scale=0.6]{iverif-cluster1.png} 
	\caption{Vérification du noeud 1}
    \label{fig:VerifNoeud1}
\end{figure}
 Puis ensuite il faut ajouter des droits pour que les prochains noeuds puissent avoir les mêmes droits que le premier noeud. Pour cela il faut créer un user, ici nous allons prendre pour exemple les commandes utilisées lors de cette création de user. 
 Donc nous avons : 
 \begin{enumerate}
 \item \textbf{CREATE USER 'root'@'giroud4.asrall.iutnc.univ-lorraine.fr' IDENTIFIED BY 'pomme';}
 \item ensuite il faut attribuer les droits et la réplication : \textbf{GRANT RELOAD, LOCK TABLES, REPLICATION CLIENT ON *.* TO 'root'@'giroud4.asrall.iutnc.univ-lorraine.fr';}
 \item Et maintenant il lui faut tous les privilèges : \textbf{FLUSH PRIVILEGES;}
 \end{enumerate}
 
Après avoir attribué les droits au nouvel utilisateur, il faut maintenant configurer le noeud 2.
Comme le premier noeud il faut modifier le fichier \textbf{my.conf}.
Voici la configuration du noeud 2:
\begin{figure}[h]
    \centering
\includegraphics[scale=0.5]{noeud2-perco.png} 
    \caption{Configuration du noeud 2}
    \label{fig:ConfigNoeud2}
\end{figure}
Après avoir configuré le noeud 2, relancer le service comme ceci: \textbf{/etc/init.d/mysql start}.
Comme le noeud 1, vérifier le statut du cluster toujours avec la commande :
\textbf{show status like 'wsrep\%';} (dans MySQL).Nous avons donc 

\begin{figure}[H]
    \centering
\includegraphics[scale=0.6]{iverfi-noeud2.png} 
    \caption{Vérification de l'intégration dans le cluster via MySQL}
    \label{fig:VerifNoeud2}
\end{figure}
Nous pouvons donc voir que le noeud N\degre2 fait maintenant parti du cluster !

Ensuite pour le dernier noeud (le N\degre3) nous allons une nouvelle fois modifier 
le fichier de configuration \textbf{my.conf}. Notre configuration pour le noeud 3
est la suivante:
\begin{figure}[H]
    \centering
\includegraphics[scale=0.5]{noeud3-perco.png} 
    \caption{Configuration du noeud 3}
    \label{fig:ConfigNoeud3}
\end{figure}
Comme pour le noeud précédent, relancer le service avec une nouvelle 
fois la commande \textbf{/etc/init.d/mysql start}
Nous allons faire une ultime vérification pour voir si la noeud N\degre3 
est bien intégré dans le cluster avec la commande \textbf{show status like 'wsrep\%';}
\begin{figure}[h]
    \centering
\includegraphics[scale=0.6]{iverif-noeud3.png} 
    \caption{Vérification de l'intégration dans le cluster via MySQL}
    \label{fig:VerifNoeud3}
\end{figure}
Nous pouvons maintenant constater que le noeud 3 est bien intégré dans le cluster !

\subsection{Test de la réplication}

Après l'installation de notre cluster, voici le moment important à tester, 
\textbf{la réplication}. Pour cela, nous allons réaliser un ensemble de requétes 
SQL et voir comment réagit notre cluster.\\
Pour commencer, nous allons créer une base de données sur le noeud 2, pour cela rien de plus simple:

\begin{figure}[H]
    \centering
\includegraphics[scale=0.7]{TestReplication1.png}
\caption{Création d'une base}
    \label{fig:Testrepli1}
\end{figure}
L'étape suivante est d'aller sur l'un des deux autres noeuds (ici nous allons prendre le noeud 1) et créer une table dans la base Percona.
\begin{figure}[H]
    \centering
\includegraphics[scale=0.7]{Testreplication2.png} 
\caption{Création d'une table}
 \label{fig:Testrepli2}
 \end{figure}
Et la dernière étapes (il faut tester tous nos noeuds pour être sûr) nous allons insérer des données dans la table Percona.
\begin{figure}[H]
    \centering
\includegraphics[scale=0.7]{TesteReplication3.png}
\caption{Insertion de données}
    \label{fig:Testrepli3}
\end{figure} 

Maintenant, la verification ultime, nous allons vérifier que les données ont été
répliquées, pour cela nous allons nous connecter sur un noeud, par exemple le N'3.
\begin{figure}[H]
    \centering
\includegraphics[scale=0.7]{TestUltimeReplication.png} 
\caption{Vérification}
    \label{fig:Testrepli4}
\end{figure} 
Et voila ! Nous pouvons constater que notre cluster est fonctionnel ainsi que la réplication ! Grâce à cette partie nous avons pu voir que nous avons pu mettre en place assez facilement un cluster de base de données avec Percona ainsi qu'une réplication des bases de données.

%\section{Sécurité}
%\input{installsecurite.tex}


\section{Autres}
\input{installautres.tex}


\chapter{Conclusion}
\input{conclusion.tex}

\part{Annexes}
\chapter{Sources/Webographie/Bibliographie}
\input{sources.tex}


\chapter{Scripts et configurations}

\section{Script d'installation général}
\label{lst:bashinstall}
\lstinputlisting[style=code]{code/install2.sh}

\section{Script d'installation haproxy avec LXC}
\label{lst:scriptha}
\lstinputlisting[style=code]{code/haproxy.sh}

\section{/etc/network/interfaces Ha Proxy Hôte}
\label{lst:interfaces}
\lstinputlisting[style=code]{code/interfaces}

\section{haproxy.cfg}
\label{lst:haproxycfg}
\lstinputlisting[style=code]{code/haproxy.cfg}

\section{dnsmasq.hosts}
\label{lst:dnshosts}
\lstinputlisting[style=code]{code/dnsmasq.hosts}

\section{dnsmasq.conf}
\label{lst:dnsconf}
\lstinputlisting[style=code]{code/dnsmasq.conf2}
(il ne s'agit pas de la configuration intégrale, juste des parties que nous utilisons).

\printglossaries

\end{document}
