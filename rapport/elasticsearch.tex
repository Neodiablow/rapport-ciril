\definecolor{grey}{HTML}{CCA3A3}
%couleur pour API REST

\begin{figure}[H]
\center
\includegraphics[width=0.2\textwidth]{elasticsearch.png}
\label{fig:elasticsearchlogo.png}
\end{figure}

\section{Présentation de Elasticsearch}
Elasticsearch est moteur de recherche et d'analyse en temps réel. Il permet l'exploration
de données de façon très rapide par des recherches, que ce soit par des recherches
\gls{fulltext}, ou bien des recherches structurées.

Elasticsearch est depuis peu développé par la société \emph{Elastic}. C'était, à 
la base, un projet du développeur Shay Banon, qui souhaitait concevoir une API simplifié
pour la bibliothèque de moteur de recherche : Apache Lucene\fnu[Page du projet Lucene ]{https://lucenenet.apache.org/}.

Elasticsearch et la stack ELK est en passe de devenir un standard dans l'industrie.
En effet le logiciel à une utilisation assez versatile, de l'aide à la prise de 
décision en temps réelle à l'analyse de code source. Et à l'heure actuelle, la capacité 
à exploiter les masses de données et de méta données accumulées chaque jour devient 
un enjeu économique majeur (mais pas seulement \ldots). Enfin l'un des principaux 
atouts d'Elasticsearch réside dans son aptitude à pouvoir passer à l'échelle simplement.

\footnotesize{\emph{Attention, ce chapitre ne sera qu'une présentation très succinte des possibilités 
du logiciel Elasticsearch, tout détailler nécessiterait \emph{sans doutes} des milliers
de pages, le résumé officiel\footnote{Elasticsearch : The Definitive Guide, disponible 
chez Pearson et Github https://github.com/elastic/elasticsearch-definitive-guide}
en fait déjà \emph{plus de 950} \ldots}}

\section{Installation}
Avant même de regarder les différentes dépendances nécessaires à l'utilisation de
Elasticsearch il est recommandé de vérifier que l'on utilise bien la même version
que son compère Logstash (vérifier la compatibilité dans la documentation si les
versions de Logstash et Elasticsearch ont un numéro différent).

Son installation est sensiblement la même que son comparse logstash puisque ce logiciel 
nécessite également l'installation des dépendances \emph{jruby} et \emph{openjdk-7-jre}
à noter qu'il fonctionne également sur openjdk-8-jre.

Là aussi les paquets debian officiels n'existant pas on utilisera celui fourni par 
\hyperref[https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.5.1.deb]{elastic.co}.
Et ici aussi le paquet est un peu approximatif puisqu'il faut rajouter certains 
chemin, et ajouter des droits.

\subsection{Configuration de base}


{\huge Acompleter et revoir}
p24-26
 test


\section{Sense}
Sense est un module chrome développé par Boaz Leskes. Il sert de client à ElasticSearch
pour éviter d'avoir à le manipuler directement via curl.

Le développement (public) de ce module est arrêté depuis son intégration dans \emph{Marvel} 
le logiciel de monitoring et d'optimisation, vendu\footnote{voir basde page : 
\url{https://www.elastic.co/products/marvel/signup.html}} par la société \emph{elastic}.


\subsection{Installation}
C'est simple comme installer une extension Chrome\footnote{testé sur chromium} tierce.
Tout d'abord : récupérer le module à l'adresse \url{https://github.com/bleskes/sense}
en utilisant par exemple : 
\begin{lstlisting}[style=code,label=lst:gitclonesense]
git clone https://github.com/bleskes/sense.git
\end{lstlisting}

Il suffit ensuite de l'activer dans chromium :\\ 
chrome://extension => Developer mode => Load unpacked extension.
\begin{figure}[H]
\center
\includegraphics[width=12cm]{senseinstall.png}
\label{fig:senseinstall}
\caption{Plugin Sense installé dans chromium}
\end{figure}
Et voilà ! \footnotesize{(avec un accent anglais)}
\subsection{Utilisation de Sense}
Voic l'interface de Sense :

\begin{figure}[H]
\center
\includegraphics[width=15cm]{sensegui.png}
\label{fig:sensegui.png}
\caption{Vue générale de Sense}
\end{figure}

La difficulté se situe évidemment plutôt du coté de l'appréhension, la configuration
et l'optimisation de Elasticsearch.

Nous allons avec l'image ci-dessous \ref{fig:sensegui2.png} brièvement expliquer le fonctionnement de Sense
\begin{figure}[H]
\center
\includegraphics[width=15cm]{sensegui2.png}
\label{fig:sensegui2.png}
\caption{Zoom sur les fonctionnalités de Sense}
\end{figure}
Le formulaire \textbf{Server} situé en haut correspond à l'adresse et au port d'écoute 
de l'instance Elasticsearch sur laquelle on souhaite travailler.

Le panneau de gauche correspond au \textbf{panneau de requête}. On utilise l'api 
REST d'Elasticsearch pour envoyer des requêtes (recherches, modifications\ldots 
une présentation de l'API est réalisé ultérieurement). Il est à noté que le panneau 
de gauche est doté d'une autocomplétion pour les fonctions et les éléments standards 
d'Elasticsearch.

Le panneau de droite est le \textbf{panneau de réponse} aux requêtes. Les informations
nous parviennent en JSON.

\section{La théorie}
{\huge A compléter}

\subsection{Approximation et comparaison avec le modèle relationnel}
La comparaison entre Elasticsearch et une base de données n'est pas forcement heureuse,
c'est un moteur de recherche (d'indexation), pas une base de données. 
%Il utilise donc la notion d'index qu'on peut cependant assez facilement comparer au modèle relationnel.

Elasticsearch s'organise autour d'index que l'on peut comparer aux bases (de données)
dans le modèle relationnel, un index peut utiliser plusieurs types\footnote{Dans 
notre projet \textbf{nous n'avons pas fait ce choix} pour pouvoir plus facilement 
modifier les mappings sans supprimer toutes les données. Il aurait été envisageable
par exemple de différencier les logs firewall des logs \textit{states} en utilisant 
les types. Cf partie 3}, ils s'apparentent aux tables dans le modèle relationnel. 

Chaque enregistrement d'Elasticsearch est effectué sous forme document. Les documents
sont nécessairement rangé dans un type, éventuellement type par défaut. Le document 
peut être comparé à une ligne (row). 

Ces lignes sont constitués de colonnes, appellées champs (ou fields) dans Elasticsearch.

\begin{figure}[H]
\textbf{BDD Relationnelle $\Rightarrow$ Base de données $\Rightarrow$ Tables $\Rightarrow$ Ligne $\Rightarrow$ Colonnes\\
Elasticsearch \hspace{7mm} $\Rightarrow$ \hspace{8mm }Index \hspace{8mm} $\Rightarrow$ \hspace{3mm}Types \hspace{3mm} $\Rightarrow$ Documents $\Rightarrow$ Champs}
\end{figure}


\section{L'infrastructure}
Dans cette partie nous allons expliquer comment fonctionne Elasticsearch à plus bas 
niveau. Nous allons parler de noeuds, de shards, d'instances\ldots

Comprendre cette partie est nécessaire pour pouvoir paramétrer une installation simple 
nous expliquerons briêvement les enjeux pour un cluster plus imposant.
\subsection{La base}
\subsubsection{Grappes et nœuds}
Chaque instance d'Elasticsearch fonctionne nécessairement dans une entité abstraite 
appelé cluster (grappe), c'est son groupe. On peut avoir un cluster d'une seule instance.
Les clusters son identifiés par des noms.

Une instance est appelé \emph{node} (nœuds). Il est possible de lancer plusieurs nodes  
par machines mais c'est déconseillé (cf partie tuning).

Les nodes partagent leurs données et la charge de travail au sein du cluster. Le 
cluster est capable automatiquement de répartir équitablement ses données entre 
les nodes, et ce même lors de l'ajout ou la suppression d'un node.

Il existe un/footnote{dans de grosses infrastructure il est possible d'en avoir plus
pour aider à la gestion du cluster} master node qui est élu au sein du cluster. 
Ce node est chargé de la gestion du cluster ajout ou suppression des des nodes, des  
index. Si le trafic dans le cluster augmente suffisamment le master node peut n'être 
dédié qu'à cette tache.

\subsubsection{Shards}
On a vu précédemment que les index sont l'endroit où sont stocké les données. Un 
index est un \textit{namespace logique} qui pointe vers un ou plusieurs shards.

Un shard (éclat) contient une fraction de toutes les données de  son index. Dans 
le cas ou index n'aurait qu'un seul shard (il en a 5 par défaut), ce shard contiendrait
l'index entier.
Chaque shard est une instance de Apache lucene. Chaque shard est un moteur de recherche
complet, mais ne possedant qu'une fraction des données d'un index entier.

Les applications utilisant Elasticsearch (comme Kibana) ne dialogue qu'avec les index
la couche d'abstraction au dessus des shards, justement parce que les informations 
d'un shard sont parcellaire.

Il existe deux types de shards les shards primaires, et les shards répliqués.
Les shards répliqués sont des copies de shards primaires, ils servent à accélérer
le traitement des requêtes Elasticsearch, ils peuvent également servir de \emph{failover} 
en cas de défaillance d'une machine.

Le nombre de shards \textbf{primaire} attribué à chaque index est fixe et ne peut 
pas être changé au cours de la vie de l'index. Il est en revanche tout à fait possible
d'ajouter ou de supprimer des shards répliqués.

\subsubsection{Redondances et montées à l'échelle}
Dans cette partie en plus du fonctionnement du cluster et de la répartition des shards
nous évoquerons sa santé. Un cluster est considérer en bonne santé lorsque tous ses
shards sont répliqués au moins une fois (\textit{failover}).

Nous prendrons ici l'exemple d'un index \emph{blog} possédant 3 shards primaires. 
\footnote{Exemple inspiré et images tirées de \textit{A definitive guide to Elasticsearch}}
Nous souhaitons que chaque shard primaire soit répliqué une fois (donc trois shards
répliqués). Cette figure de style n'est pas innocente, le réglage de ce paramètre
\footnote{via l'API présenté après la partie sur le tuning} est présenté de la même
façon: "number\_of\_shards":3, "number\_of\_replica":1. 


\begin{figure}[H]
\center
\includegraphics[width=0.6\textwidth]{elasticsearch/clustershard1.png}
\label{fig:clustershard1}
\caption{Cluster minimal, 1 node, 1 index}
\end{figure}

La santé de notre serveur est ici considéré comme moyenne, il peut parfaitement 
fonctionner, mais touts ses shards répliqués ne sont pas  actifs. En faite aucun 
shard répliqué n'est actif. Cela n'aurait pas d'intérêt d'ajouter les shards répliqués
sur ce node, car cela n'améliorera pas le traitement des données et ne protégera pas
notre cluster contre la perte de données, en cas défaillance de son unique node.

Nous allons maintenant rajouté un node, sans changer notre configuration.

\begin{figure}[H]
\center
\includegraphics[width=0.6\textwidth]{elasticsearch/clustershard2.png}
\label{fig:clustershard2}
\caption{Cluster, 2 node, 1 index}
\end{figure}

On constate que notre cluster est maintenant redondé, le node master possède les 
shards primaires, le second node les shards répliqués. Ces actions sont effectuées
automatiquement à l'ajout du node.

La santé de notre cluster est maintenant considéré comme bonne, il peut supporter 
une panne.

Nous allons maintenant rajouter encore un node et ainsi répartir mieux la charge

\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{elasticsearch/clustershard3.png}
\label{fig:clustershard3}
\caption{Cluster, 3 node, 1 index}
\end{figure}

Cette configuration fonctionne plus efficacement que la précédente puisqu'elle a 
accès à plus de ressource et que Elasticsearch répartie intelligemment la ses ressources
et donc la charge de travail sur les différents nodes.

Remarque, si l'on perdait un node maintenant, nous nous retrouverions dans la configuration
numéro 2 (avec le failover), quitte à devoir réélir un master node. Notre état de santé,
serait toujours bon.

Pour voir des choses plus intéressantes, nous allons ajouter un shard répliqué (donc 3).

\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{elasticsearch/clustershard4.png}
\label{fig:clustershard4}
\caption{Cluster, 3 node, 1 index, mais plus de shards répliqués!}
\end{figure}


Rien de particulièrement notable.

Mais si nous enlevons le node 1\ldots

\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{elasticsearch/clustershard5.png}
\label{fig:clustershard5}
\caption{Cluster, 2 node, 1 index encore\ldots ou pas}
\end{figure}

Au moment précis de la coupure notre cluster est passé en mauvaise santé, car il 
n'avait plus de node master, et surtout des shards primaire étaient manquants.

Si une recherche avait été effectué sur cet index à ce moment précis, des résultats partiels
auraient été obtenus, ainsi qu'un avertissement du fait que toutes les données n'étaient
pas disponibles.

On constate qu'une élection de master node a eu lieu. En constatant que deux shards 
primaires sont manquant il a immédiatement promu les sards répliqués au rang de 
shard primaires.

La santé de notre cluster est maintenant considéré comme moyenne, puisque tous ses
shards répliqués ne peuvent pas être affectés.


Cette partie permet de résoudre les problèmes qui pourraient survenir (meme sur
un cluster d'une seule machine) et permet surtout de mieux comprendre le fonctionnement
interne de Elasticsearch.

\subsection{Le tuning}
Voici quelques conseils applicables dans pratiquement toutes les situations et 
permettant d'optimiser le fonctionnement d'Elasticsearch.

\subsubsection{Ne pas utiliser la swap}
Il est très fréquent (et souvent nécessaire) de formater une partition de swap pour
que le système puisse optimiser son fonctionnement. C'est très pratique pour ne pas
saturer la mémoire RAM de nos machines de bureau, notamment quand on voit la consommation
pantagruélique de certains navigateurs internet récents. Les fichiers qui ne sont 
susceptible de ne pas être utilisé avant un long moment sont parfois stockés sur le
disque dur afin de libérer de l'espace pour d'autres applications, la swap est
également utilisé lorsque l'on met un ordinateur en veille \ldots

La situation n'est pas la même sur un serveur. Ici nous sommes relativement maitre
de notre environnement, et de plus nous voulons que le service Elasticsearch soit 
le plus véloce possible, pour se faire il faut au contraire l'empêcher au maximum 
d'utiliser la partition de swap (forcément plus lente).

Il existe plusieurs façon de faire (y compris ne pas utiliser de partition de swap)
celle que j'ai choisie d'utiliser est de modifier la variable \ipath{vm.swapiness}
dans le fichier \ipath{/etc/sysctl.conf}. La swapiness représente le pourcentage
de mémoire RAM restant à partir duquel on commence à envoyer de informations en
swap.

\begin{lstlisting}[style=code,label={lst:configswapiness},caption={Configuration swapiness}]
vm.swapiness = 2
swapoff -a
swapon -a
\end{lstlisting}
Il existe deux méthodes pour que le changement de swapiness soit pris en compte :
redémarrer la machine ou bien désactiver puis réactiver la swap, via les commandes
swapon, swapoff. Utiliser la commande swapoff est également une mesure radicale à 
notre problème.

\subsubsection{Utiliser une quantité de RAM raisonné}
Elasticsearch est limité par Java. Avant de parler de ces limites, il faut rappeler 
que Elasticsearch est un front-end à Apache Lucene. Lucene est conçu pour tirer 
parti très efficacement du cache des système de fichiers (probablement ext4 si 
vous utilisez Debian), qui sont en définitif, gérer par le 
noyau\footnote{https://www.elastic.co/guide/en/elasticsearch/guide/current/\_limiting\_memory\_usage.html}.
Il est conseillé par la documentation de donner au maximum 50\% de la mémoire RAM
disponible à Elasticsearch, le reste étant dévouer à lucène et au bon fonctionnement
du système.
Dans notre installation dont nous parlerons plus en détail ultérieurement, nous 
avons choisi de nous réserver une bonne marge de manœuvre puisqu'un redis et un Logstash
minimalistes tournent en sus sur la machine hébergeant Elasticsearch.

Cependant cette valeur de 50\% n'a de sens que si Elasticsearch consomme moins de 
32Go de RAM, en effet, en allouer plus devient contreproductif puisque jusqu'à 32Go
la machine virtuelle Java (JVM) \textit{compresse} les adresses des pointeurs, 
(tant qu'on reste sous la limite des 32Go de RAM on peut continuer à utiliser les 
adresses mémoires sur 4 octets), après, la consommation de mémoire explose et le
\textit{garbage collector} devient bien moins efficace.

Pour les machines possédant une énorme quantité de mémoire RAM (128Go à 1To)
il conseiller pour optimiser le fonctionnement de la machine de faire tourner plusieurs
noeuds d'Elasticsearch dessus (attention aux entrées sortie et à l'utilisation processeur).

\subsection{Faire du nettoyage régulièrement}
Plus Elasticsearch agrège des données plus il s'empâte, ce phénomène est inévitable 
sur le long terme. Les contre-mesures sont de scale-out (monter à l'échelle horizontalement)
en rajoutant de nouveaux nœuds à notre cluster elastic search. On s'appliquera à 
manager les shards de façon optimisé bref à faire du fine tuning.

Pour éviter ce ralentissement la solution la plus radicale reste de supprimer les 
données. Justement, dans le cadre de notre projet, nous n'avons pas besoin de conserver 
toutes les données sur le long terme. Nous avons donc décider de supprimer les logs 
de changement d'état des par-feu tous les 4 jours. Ces logs peuvent représenter 
jusqu'à 30Go de données journalières. 
Pour ce faire nous utiliserons un tâche \textbf{cron} couplé à un script bash 
\ref{lst:scriptdelindex} tirant parti de l'API d'Elasticsearch dont nous parlerons 
plus bas. Pour indication, les index de firewall son supprimés tous les 4 jours, 
(une requête judiciaire/alerte sécurité arrive en général en moins de 3 jours).\\ 
Les logs sont de toute façon également conservés ailleurs pour se soumettre aux 
imperatifs judiciaires. Les index d'état (intéressants pour établir des statistiques)
sont conservés 1 mois.\\
Remarque sur la commande curl et son utilisation dans cron

\begin{lstlisting}[style=code,label={lst:curlexemple},caption={Extrait de notre script \ref{lst:scriptdelindex}}]
curl -sS -XDELETE $blade:$port/$target-$d
\end{lstlisting}

On remarque ici l'utilisation de l'option -sS pour \textit{silent, Show errors}.
Ainsi cron n'est pas importuné par les retour sur la sortie standard cela permet
également, en ajoutant la directive \textbf{MAILTO: mail@example.fr} de renvoyer
la sortie d'erreur vers mail@example.fr. Cela nécessite évidemment d'avoir configurer
un serveur mail sur notre machine, par défaut sur Debian, Exim (dpkg-reconfigure 
exim-config).

Concernant -XDELETE c'est une utilisation de l'API REST décrite plus bas.

Une des stratégies préconisé dans le cas où l'on souhaite conserver des données sur
le long terme alors qu'on en a seulement un besoin d'accès et d'analyse ponctuel ;
consiste à les enregistrer dans des fichiers séparés (output Logstash) et de les 
faire ingérer à un cluster Elasticsearch dimesinonné en conséquence le moment venu.



\section{Les API Elasticsearch}
Elasticsearch est énorme, mais être assez facilement utilisable par le 
plus grand nombre, des \gls{API} \emph{optimisées} pour chaque tâches ont été conçues.

\subsection{API REST}
Cette API sert à la communication avec Elastisearch, comme toutes les API REST elle
utilise les méthodes HTTP, ici : GET, POST, PUT et DELETE et s'appuie ensuite sur l'architecture d'Elasticsearch.

\textbf{{\color{grey}http://host:port}/[{\color{red}index}]/[{\color{cyan}type}]/[{\color{yellow}\_action/id}]}\\[5mm]
Imaginons que dans un projet fictif, nous souhaitions référencer des tweets.
On pourrait procéder comme suit pour ajouter le premier.

\textbf{PUT  {\color{grey} http://100.127.255.1:9200}/{\color{red}twitter}/{\color{cyan}tweet}/{\color{yellow}1}}

\begin{lstlisting}[style=code,label={lst:RESTexemple1curl},caption={Avec curl}]
curl -XPUT http://100.127.255.1:9200/twitter/tweet/1
\end{lstlisting}
Voici le résultat en utilisant curl, directement en ligne de commande, par 
navigateur, \ldots

\begin{lstlisting}[style=code,label={lst:RESTexemple1sense},caption={Avec Sense}]
PUT /twitter/tweet/1
\end{lstlisting}

Voici la syntaxe que nous obtiendrions en utilisant Sense, puisque notre serveur 
et notre port sont déjà renseignés, la syntaxe est bien plus courte.

La directive PUT est utilisé pour renseigner de nouvelles informations dans Elasticsearch.


Dans notre projet d'analyse de logs, il est fréquent que nous dussions supprimer 
des index, notamment dans le cas du paramétrage des \emph{mappings}, mais également
pour soulager notre infrastructure du poids des logs de firewall (~20-30Go/jours).\\

\textbf{DELETE  {\color{grey} http://100.127.255.1:9200}/{\color{red}twitter}/}\\

Si nous avions un index twitter journalier il serait possible d'utiliser une commande
très similaire pour supprimer tous les indexs d'un seul coup :\\

\textbf{DELETE  {\color{grey} http://100.127.255.1:9200}/{\color{red}twitter*}}\\

La directive DELETE est utilisé pour supprimer des informations d'Elasticsearch.\\


Enfin la directive GET qui sert à récupérer des information, à tout niveaux, index,
type, mapping, type par défaut \ldots, en revanche il faut avoir un identifiant exact,
ce n'est pas un outils de recherche (abordé dans la section suivante).\\[5mm]
\textbf{GET  {\color{grey} http://100.127.255.1:9200}/{\color{red}twitter}/{\color{cyan}tweet}/{\color{yellow}1}}\\

Les information récupérées le sont en JSON.

\subsection{Les API de recherche}
DSL pour Domain Specific Language, parce que Elasticsearch est avant tout un moteur 
de recherche, il dispose de puissantes fonctionnalités de recherche. Il dispose donc
de son propre langage d'interrogation le QueryDSL. C'est loin d'être un cas unique,
par exemple Puppet dispose également de son propre langage de configuration.

Il existe plusieurs API (ou méthodes) de recherche dans Elasticsearch nous les  
détaillerons plus en détail après avoir expliquer le fonctionnement général d'une
recherche dans Elasticsearch.

La recherche dans Elasticsearch est particulièrement efficace, car Elasticsearch 
indexe tout le contenu de ses documents (il indexe chaque field, en fonction d'un
mapping (discuté plus bas)).
C'est pour permettre l'indexation qu'Elasticsearch utilise du JSON structuré.



\subsubsection{Empty Search}
C'est la forme la plus basique de l'API de recherche, on ne spécifie pas de requête
spécifique. Comprendre le fonctionnement et les possiblité de cette API basique 
permettra d'utiliser plus efficacement SearchLite, qui en est l'évolution directe.


\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample1},caption={le "Hello World" de la recherche}]
GET /_search
\end{lstlisting}

Cette requête retourne tous les documents, de tous les index du cluster duquel nous
sommes membre.

\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample2},caption={Réponse type à notre requête précédente}]
{
    "took": 798,
    "timed_out": false,
    "_shards": {
        "total": 201,
        "successful": 201,
        "failed": 0
    },
    "hits": {
        "total": 353585048,
        "max_score": 1,
        "hits": [
        {
            "_index": ".kibana",
            "_type": "visualization",
            "_id": "Top5-nat-firewall-router",
            "_score": 1,
            "_source": {
                "title": "Top5 nat-firewall router",
                "visState": "{\"type\":\"histogram\",\"params\":{\"shareYAxis\":true,\"addTooltip\":true,\"addLegend\":true,\"mode\":\"stacked\",\"defaultYExtents\":false},\"aggs\":[{\"id\":\"1\",\"type\":\"count\",\"schema\":\"metric\",\"params\":{}},{\"id\":\"2\",\"type\":\"terms\",\"schema\":\"group\",\"params\":{\"field\":\"IPnat\",\"size\":5,\"order\":\"desc\",\"orderBy\":\"1\"}}],\"listeners\":{}}",
                "description": "",
                "version": 1,
                "kibanaSavedObjectMeta": {
                "searchSourceJSON": "{\"index\":\"firewall-*\",\"query\":{\"query_string\":{\"query\":\"*\",\"analyze_wildcard\":true}},\"filter\":[]}"
                }
            }
        },
        .... 9 Autres ...
    }
}
\end{lstlisting}

Quelques explications :

\paragraph{hits}
L'élément hits contient des informations sur la requête et les réponse à la requête.
\textit{total} représente le nombre total de documents retournés pour cette requête, ici le 
nombre total de documents indexés: 353585048. 
Cela signifie qu'au moment de la requête il y avait environ 353 millions de lignes
de logs indexés dans notre Elasticsearch au moment de la requête.

Les réponses à la requête nous sont renvoyées dans l'array \textit{hits}, par défaut
seul les 10 premiers documents satisfaisant notre requête nous sont renvoyés 
(comme il n'y avait pas de requête, simplement les 10 premiers documents).

Les documents renvoyés dans l'array sont classés en fonction de leur \_score, une 
fois encore, puisque nous n'avons rien précisé dans notre requête, tous les résultats 
nous sont renvoyés avec le score 1.

On notera que le \ipath{max\_score}, score maximum obtenu lors de la requête.

Enfin on remarque que le source (tous les champs indexés) de chaque document est présent
dans la réponse à la requête.

\paragraph{took}
Took est le temps en millisecondes pris pour effectué cette requête, ici 798

\paragraph{shard}
L'élément \_shards, nous indique le nombre de shards utilisé lors de la requête. 
Dans combien de shards tout c'est bien passé, dans combien il y a eu des erreurs,
les erreurs sont très peu probables, cela se produit généralement sur un cluster 
de plusieurs machines, lorsque plusieurs d'entre elles sont inacessibles (il faut 
que les primary et replica d'un shard soient inaccessible en même temps).

\paragraph{timeout}
Il est possible d'effectuer une recherche \textit{par timeout}, cela signifie que 
Elasticsearch va effectuer sa recherche de façon classique, mais que lorsque le temps
nécessaire à la recherche dépassera un temps déterminé, il renvera les informations 
qu'il a eu le temps de rassembler, toujours dans l'ordre qui lui semble le plus pertinant
(ordonné par score). Attention cependant, cela ne nous absouds pas pour autant du
coût de la recherche. Si les shards renvoient bien les résultats pertinents au moment
souhaité, cela n'arrête pas pour autant la requête qui finira de s'executer en arrière
plan.

\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample3},caption={Une recherche "vide" avec timeout}]
GET /_search?timeout=10ms
\end{lstlisting}


\paragraph{Recherche multi-index et multitype}
La recherche multi-index et multitype est toujours possible comme dans l'API REST

\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample4},caption={Une recherche multi-index ...}]
GET /gb,us/_search
GET /g*,u*/_search
GET /gb,us/user,tweet/_search
\end{lstlisting}

\paragraph{Pagination}
Par défaut lors d'une requête Elasticsearch renvoit seulement les 10$^{ers}$ résultats.
Il est biensure possible de paramétrer cela, pour afficher plus de résultats, et pas
forcément les plus pertinents (ceux qui présente le score le plus élevé).\\
\textbf{size} permet d'indiquer le nombre de résultats souhaités\\
\textbf{from} permet d'indiquer le nombre de résultats que l'on souhaite sauter.

\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample4},caption={Pagination}]
GET /_search?size=5&from=10
\end{lstlisting}


\subsubsection{Search Lite}
Comme expliqué avant il existe deux forme d'API de recherche. L'API lite avec requête
en chaine de caractères \textit{(string query)} et l'API \textit{"full body request"},
qui nécessite comme corps de la requête, du JSON.

Pour utiliser la recherche SearchLite, nécessite simple d'ajouter en sus de notre
empty search \emph{?q=} et la requête. Attention si vous utilisez cette API avec 
curl il pourrait être nécessaire d'utiliser la syntaxe http (\%2B pour + par exemple).

\begin{lstlisting}[style=code,label={lst:APIsearchliteexample1},caption={Exemples simples}]
GET /_search?q=epinal
GET /state-2015.05.22/_search?q=epinal
\end{lstlisting}

Ici on cherche le terme \emph{epinal} dans tous les champs, c'est par fois utile,
mais dans de nombreux cas nous connaissons déjà le nom du champ (cf \hyperref[lst:grokregex1]{Logstash}) dans
lequel nous souhaitons avoir le terme. 

Pour se faire il suffit d'utiliser la syntaxe suivante : 
\begin{lstlisting}[style=code,label={lst:APIsearchliteexample2},caption={Choix du champ}]
GET /_search?q=logsource:epinal
\end{lstlisting}

Bien plus intéressant, il est possible d'imposer des conditions à remplir ie: doit
contenir le terme suivant, ou au contraire ne doit \textbf{pas} contenir le terme 
suivant.

\begin{lstlisting}[style=code,label={lst:APIsearchliteexample3},caption={Conditions must (not) match}]
GET /_search?q=+logsource:*epinal* -logsource:sw*
\end{lstlisting}

Dans l'exemple précédant on souhaite chercher les équipement réseaux situés à epinal
mais pas les switchs.
L'utilisation des + et - change vraiment le sens de la requête, dans la précédante
sans les symboles, la présence ou non augmentait la pertinence des réponses contenant
le terme recherché, mais n'était pas discriminante.
Avec ces symboles, on exclu les réponses qui ne se conforment pas à nos exigences.


La précense des \textbf{*} sera explicité dans la partie sur la recherche full text
{\scriptsize \textit{(prise d'Aspirine\texttrademark conseillée)}}.


Il existe un autre moyen d'influencer la pertinence des résultats (de faire remonter
en haut de liste ce qui nous intéresse le plus).
Cela est particulièrement pratique dans les longues requêtes.
Il s'agit de l'opérateur \textbf{\^} qu'on n'utilise en général en conjonction de
parenthèses (qui servent simplement à faire des groupes).


\begin{lstlisting}[style=code,label={lst:APIsearchliteexample4},caption={Modifier la pertinence}]
GET /_search?q=+logsource:*epinal* -logsource:sw* (timestamp:May)^10 Power
\end{lstlisting}
Dans cette requête nous cherchons toujours des équipements non switch situés à Epinal.
Nous somme cette fois ci très intéressés par ce qui s'est passé en Mai et d'autant
plus si cela concerne un problème d'alimentation éléctrique.

Concernant la gestion du temps, et des timestamp, nous allons voir une propriété 
intéressante d'Elasticsearch lorsque le mapping de l'index est bien réalisé.
Il est capable de \textit{s'orienter} dans le temps à partir d'un champ texte.
Cela n'est pas forcément très utile si l'on utilise Kibana, puisque son interface
nous permet très facilement d'être plus précis, mais cela laisse imaginer les possiblités
d'Elasticsearch.


\begin{lstlisting}[style=code,label={lst:APIsearchliteexample5},caption={Le temps dans SearchLite}]
GET /_search?q=+logsource:*epinal* -logsource:sw* (timestamp:>Jun)^10 Power
GET /_search?q=+logsource:*epinal* -logsource:sw* (timestamp:=<Jun)^10 Power
\end{lstlisting}

SearchLite accepte les opérateur $< > =< =>$ et Elasticsearch est capable de les 
interprété pour peu que le champ soit \textit{mappé comme date}(cf Mapping).

Il est possible d'utiliser les opérateurs logiques \textbf{OR} et \textbf{AND} 
dont l'utilisation est assez évidante \ldots
\begin{lstlisting}[style=code,label={lst:APIsearchliteexample6},caption={Opérateurs logiques}]
+IPoutside:"8.8.8.8" +IPnat:"8.8.4.4" +(portnat:"37657" OR portnat:"19474")
\end{lstlisting}

Il faut faire attention à l'utilisation des symboles -, :, /," qui on une signification.


Remarque générale, les syntaxes présentées jusqu'à présent son utilisables telles
quelles dans Sense, et en retirant \ipath{GET /\_search?q=} dans Kibana.


\subsubsection{Full-Body Search et QueryDSL}

\section{Le mapping et l'analyse}
\subsection{Mapping}
Le mapping est strictement comparable au schéma d'une base, dans le modèle relationnel.
Le mapping définit donc le "type" de nos "champs", attention on fait rentrer dans 
le mapping plus que dans le schéma d'une base (analyse, indexation, \ldots).

Il y'a un mapping différent par index (il existe aussi des templates, applicable 
à plusieurs index). Pour accéder au mapping d'un index il suffit dans Sense de lancer
la requête suivante.

\begin{lstlisting}[style=code,label={lst:mappingget1},caption={Obtenir un mapping}]
GET /firewall-2015.05.07/_mapping
\end{lstlisting}

Et voici un résultat :

\begin{lstlisting}[style=code,label={lst:mappingresult},caption={Exemple de mapping}]
{
    "firewall-2015.06.10": {
        "mappings": { "syslog": {"properties": {
                    "@timestamp": {
                        "type": "date",
                        "format": "dateOptionalTime"
                    },
                    "@version": {
                    "type": "string"
                    },
                    "IPinside": {"type": "string"},
                    "IPnat": {"type": "string},
                    "IPoutside": {"type": "string"},
                    "action": {"type": "string"},
                    "chiffre": {"type": "integer"},
                    "datetest": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "firewall": {"type": "string"},
                    "host": {"type": "string"},
                    "information": {"type": "string"},
                    "logsource": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "message": {"type": "string"},
                    "numero": {"type": "string"},
                    "operation": {"type": "string"},
                    "portin": {"type": "string"},
                    "portnat": {"type": "string"},
                    "portout": {"type": "string"},
                    "program": {"type": "string"},
                    "reste": {"type": "string"},
                    "tags": {"type": "string"},
                    "timestamp": {"type": "string"},
                    "type": {"type": "string"}
        }}}
    }
}
\end{lstlisting}


On remarque que beaucoup de champs ont pour type \textbf{string}, c'est le type choisi
par défaut.

Bien qu'ils ne soient pas utilisés ici il existe d'autres types de base, il est aussi
possible d'en définir soi-même, cela ne sera pas abordé dans ce rapport.

Types par défaut :
\begin{itemize}
    \item   boolean: true/false
    \item   long: nombres entiers
    \item   double: nombres à virgule
    \item   string: chaine de charactères
    \item   date:   une date valide, (voir la doc pour les normes acceptées)
\end{itemize}

Pour créer un nouveau mapping, il faut au préalable supprimer le précédent, (supprimer 
l'index auquel est attaché le mapping).


\begin{lstlisting}[style=code,label={lst:mappingiput1},caption={Changer le mapping d'un index}]
DELETE /firewall-2015.05.07
PUT /firewall-2015.05.07/
{
    "mappings": {
    ....
             "properties": {
                "@timestamp": {
                "type": "date",
                "format": "dateOptionalTime"
                },
                "@version": {
                "type": "string",
                "index": "not_analyzed"
                },
                "IPinside": {
                "type": "ip",
                "index": "analyzed",
                "store": "yes"
                },
                "IPnat": {
                "type": "string",
                "index": "not_analyzed",
                "norms": {
                "enabled": false
                },
                }
                ....
            }
    }
}
\end{lstlisting}

La requête entière est trop longue pour être affiché, donne une idée de la forme.
Une méthode efficace pour générer la sienne est d'utiliser celle créer par Elasticsearch
par défaut puis de la raboter et de la modelé à notre convenance.

Cette méthode est pratique pour faire des tests mais elle ne concerne qu'un seul 
index. Dans le projet nous travaillons avec de multiples index, il sera plus pratique
d'utiliser les templates pour que le même modèle s'applique partout où nous le souhaitons.

Autre remarque, si vous faites la manipulations ci-dessus dans un environnement de 
production, il y a toutes les chanches pour que Elasticsearch vous renvoie une erreur.
En effet Logstash créer par défaut de nouveaux index. Si on supprime l'index du  
jour (on perd les données), il sera recréer avec le template par défaut presque 
instantanément puisque logstash reçoit environ \textbf{500logs/s}. Pendant les tests
il peut être utile d'éteindre Logstash.

Pour créer un template, il faut simplement supprimer l'ancien et écrire le nouveau.
Il est également conseillé de supprimer les anciens indexs utilisant un mapping 
différents. Ils seront \textbf{toujours utilisables dans Sense}, mais seront 
\textbf{incohérents aux yeux de Kibana} et empêcheront de faire des recherches.


\begin{lstlisting}[style=code,label={lst:mappingput2},caption={Ajouter un template de mapping}]
(DELETE /state-2015.05*)
DELETE /_template/state-log

PUT /_template/state-log
{
"template": "state-*",
"order": 1,
"settings": {"number_of_shards": 5},
"mappings": {
    "syslog": {
        "properties": {
            "@timestamp": {
            "type": "date",
            "format": "dateOptionalTime"
            },
            "@version": {
            "type": "string"
            },
            "action": {
            "type": "string",
            "index": "not_analyzed"
            },
            "chiffre": {
            "type": "integer"
            },
            "datetest": {
            "type": "date",
            "format": "MMM d H:m:s"              
            },
            "firewall": {
            "type": "string"
            },
            "host": {
            "type": "string"
            },
            "information": {
            "type": "string"
            },
            "logsource": {
            "type": "string",
            "index": "not_analyzed"
            },
            "message": {
            "type": "string"
            },
            "reste": {
            "type": "string"
            },
            "tags": {
            "type": "string"
            },
            "timestamp": {
            "type": "string"
            },
            "type": {
            "type": "string"
            }
        }
    }
}
}
\end{lstlisting}
On constate que certains champs sont analysés et d'autres non, ces choix apparaitrons
plus clair après la partie concernant l'analyse.
Du point de vue mapping on peut noté que integer est également un type valable (liste 
exhaustive dans la documentation), on constate aussi que le type date (un type particulier
de string) qui \textbf{ne peut pas} être analysé, supporte plusieurs formats, définis
d'après la \hyperref[http://joda-time.sourceforge.net/api-release/org/joda/time/format/DateTimeFormat.html]{norme JAVA}.
Avec quelques types prédéfinis \hyperref[https://www.elastic.co/guide/en/elasticsearch/reference/1.5/mapping-date-format.html]{ici}.


\subsection{Analyse}
On remarque que certains champs ont également un \textbf{index: "not\_analyzed"}.
Tous n'en n'ont pas car il est souvent plus intéressant d'avoir des champs analysés.
Et par défaut les champs sont analysés.

Il existe trois niveaux d'indexation:
\begin{itemize}
    \item   \textbf{Analyzed}, signifie que la chaine de caractère est analysé puis indexé,
    donc cherchable en \textit{full text}.
    \item   \textbf{not\_analyzed}, le champ est toujours cherchable, mais puisqu'il n'a pas 
    été analysé, on ne peut le trouvé qu'avec sa valeur exact. \emph{Cette propriété
    peut se révéler essentielle pour réaliser des graphiques efficaces.} 
    \footnotesize{Il faut parfois savoir comment on veut exploiter ses données pour
    pouvoir les traiter en conséquence.}
    \item \textbf{no}, n'index pas ce champ, il n'est pas cherchable. Je ne me suis
    jamais servis de cette propriété, peut sans doute avoir une utilité pour l'optimisation
    de performances.
\end{itemize}

\subsubsection{Fonctionnement de l'analyse}
L'analyse consiste en deux grandes étapes, découper une chaine de charactère en termes
recherchable, puis assainissement de ces termes en enlevant par exemple les majuscules
ou en retirant les termes non pertinents (le, la, les, des \ldots), voir même en 
remplaçant des synonymes.

En faite le processus compte trois étapes. Tout d'abord le \emph{filtrage de caractères}
(faire disparaitre les / ou transformer \& en et. La tokenization (\textit{termisation}
en traduction approximative), créer un terme pour chaque chaine de caractère séparer
par un espace, une virgule, un point, \ldots{} (paramétrable cf doc). Enfin le filtre
de termes, (décris dans l'assainissement au dessus).



\subsubsection{Full text}
Le full text s'oppose aux valeurs exacts.
Les champs non analysés sont traités comme des valeurs exacts.
Comme expliqué plus haut, les chiffres, les booléens, les dates, sont des valeurs 
exacts. Il est possible qu'une chaine de caractère en soit une aussi.

\textbf{"Le chien"} est différent de \textbf{"le chien"} ou encore de \textbf{"Lechien"}.

Pour le full text la notion d'index et d'analyseur est primordiale. L'analyseur va
décidé de comment les différents membres de la chaine de caractère vont être considérés.
Après cette étape ces membres vont être indexés et une recherche les renverra par 
popularité décroissante.

Puisqu'un exemple vaut mieux qu'un long discours, je vais m'inspiré de ceux donnés
dans \textit{"The Definitive guide to Elasticsearch"}.


Considérons 2 phrases :
\begin{itemize}
    \item The quick brown fox jumped over the lazy dog
    \item Quick brown foxes leap over lazy dogs in summer
\end{itemize}

\begin{figure}[H]
\center
\begin{tabular}{|l||c|c|}
\hline
\textbf{Termes}   & \textbf{P1}    & \textbf{P2}\\ \hline  
Quick   &       &  X\\ \hline  
The     &   X   &   \\ \hline
brown   &   X   &  X\\ \hline
dog     &   X   &   \\ \hline
dogs    &       &  X\\ \hline
fox     &   X   &   \\ \hline
foxes   &       &  X\\ \hline
in      &       &  X\\ \hline
jumped  &   X   &   \\ \hline
lazy    &   X   &  X\\ \hline
leap    &       &  X\\ \hline
over    &   X   &  X\\ \hline
quick   &   X   &   \\ \hline
summer  &       &  X\\ \hline
the     &   X   &  X\\ \hline 
\end{tabular}
\caption{Index des phrase}
\end{figure}
Lors d'une recherche full text, Elasticsearch va créer ce genre de listes.

Si je cherche \emph{quick brown}, le tableau ressemblerait à cela 


\begin{figure}[H]
\center
\begin{tabular}{|l||c|c|}
\hline
\textbf{Termes}   & \textbf{P1}    & \textbf{P2}\\ \hline  
brown   &   X   &  X\\ \hline
quick   &   X   &   \\ \hline \hline
Total   &   2   &  1 \\ \hline
\end{tabular}
\caption{Index correspondant à une recherche}
\end{figure}

On voit donc bien que la phrase la plus populaire est la phrase 1. On constate également
que Elasticsearch \emph{fait une différence entre \emph{Quick} et \emph{quick}}. 
Cela est est réglable (on peut, ne pas tenir compte de la casse).
Ce qu'il faut retenir c'est que pour discriminer efficacement, il est aussi possible
d'utiliser des syntaxe comme +fox, de même on peut faire une recherche avec un bloc
de deux termes pour être plus efficace : "over the" qui n'existe que dans P1.


%\section{Plus d'information }
