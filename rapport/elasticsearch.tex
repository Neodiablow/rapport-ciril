\definecolor{grey}{HTML}{CCA3A3}
%couleur pour API REST

\begin{figure}[H]
\center
\includegraphics[width=0.2\textwidth]{elasticsearch.png}
\label{fig:elasticsearchlogo.png}
\end{figure}

\section{Présentation de Elasticsearch}
Elasticsearch est moteur de recherche et d'analyse en temps réel. Il permet l'exploration
de données de façon très rapide par des recherches, que ce soit par des recherches
\gls{fulltext}, ou bien des recherches structurées.

Elasticsearch est depuis peu développé par la société \emph{Elastic}. C'était, à 
la base, un projet du développeur Shay Banon, qui souhaitait concevoir une API simplifié
pour la bibliothèque de moteur de recherche : Apache Lucene\fnu[Page du projet Lucene ]{https://lucenenet.apache.org/}.

Elasticsearch et la stack ELK est en passe de devenir un standard dans l'industrie.
En effet le logiciel à une utilisation assez versatile, de l'aide à la prise de 
décision en temps réelle à l'analyse de code source. Et à l'heure actuelle, la capacité 
à exploiter les masses de données et de méta données accumulées chaque jour devient 
un enjeu économique majeur (mais pas seulement \ldots). Enfin l'un des principaux 
atouts d'Elasticsearch réside dans son aptitude à pouvoir passer à l'échelle simplement.

\footnotesize{\emph{Attention, ce chapitre ne sera qu'une présentation très succinte des possibilités 
du logiciel Elasticsearch, tout détailler nécessiterait \emph{sans doutes} des milliers
de pages, le résumé officiel\footnote{Elasticsearch : The Definitive Guide, disponible 
chez Pearson et Github https://github.com/elastic/elasticsearch-definitive-guide}
en fait déjà \emph{plus de 950} \ldots}}

\section{Installation}
Avant même de regarder les différentes dépendances nécessaires à l'utilisation de
Elasticsearch il est recommandé de vérifier que l'on utilise bien la même version
que son compère Logstash (vérifier la compatibilité dans la documentation si les
versions de Logstash et Elasticsearch ont un numéro différent).

Son installation est sensiblement la même que son comparse logstash puisque ce logiciel 
nécessite également l'installation des dépendances \emph{jruby} et \emph{openjdk-7-jre}
à noter qu'il fonctionne également sur openjdk-8-jre.

Là aussi les paquets debian officiels n'existant pas on utilisera celui fourni par 
\href{https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.5.1.deb}{elastic.co}.
Et ici aussi le paquet est un peu approximatif puisqu'il faut rajouter certains 
chemin, et ajouter des droits.

\subsection{Configuration de base}


Acompleter et revoir
p24-26
 test


\section{Sense}
Sense est un module chrome développé par Boaz Leskes, il sert de front-end à ElasticSearch.
Le développement (public) de ce module est maintenant arrêté. Il fait parti de 
\emph{Marvel} le logiciel de monitoring et d'optimisation, vendu\footnote{voir bas 
de page : \url{https://www.elastic.co/products/marvel/signup.html}} 
par la société \emph{elastic}.


\subsection{Installation}
Installer ce logiciel est simple comme installer une extension Chrome\footnote{testé sur chromium}
tierce.
Tout d'abord : récupérer le module à l'adresse \url{https://github.com/bleskes/sense}
en utilisant par exemple : 
\begin{lstlisting}[style=code,label=lst:gitclonesense]
git clone https://github.com/bleskes/sense.git
\end{lstlisting}

Il suffit ensuite de l'activer dans chromium :\\ 
chrome://extension => Developer mode => Load unpacked extension.

\begin{figure}[H]
\center
\includegraphics[width=12cm]{senseinstall.png}
\label{fig:senseinstall}
\caption{Plugin Sense installé dans chromium}
\end{figure}

Et voilà ! \footnotesize{(avec un accent anglais)}

\subsection{Utilisation de Sense}
L'utilisation de Sense est assez simple via son interface :

\begin{figure}[H]
\center
\includegraphics[width=15cm]{sensegui.png}
\label{fig:sensegui.png}
\caption{Vue générale de Sense}
\end{figure}

La difficulté se situe évidemment plutôt du coté de l'appréhension, la configuration
et l'optimisation de Elasticsearch.

Nous allons avec l'image ci-dessous \ref{fig:sensegui2.png} brièvement expliquer le fonctionnement de Sense
\begin{figure}[H]
\center
\includegraphics[width=15cm]{sensegui2.png}
\label{fig:sensegui2.png}
\caption{Zoom sur les fonctionnalités de Sense}
\end{figure}
Le formulaire \textbf{Server} situé en haut correspond à l'adresse et au port d'écoute 
de l'instance Elasticsearch sur laquelle on souhaite travailler.

Le panneau de gauche correspond au \textbf{panneau de requête}. On utilise l'api REST d'elasticsearch
pour envoyer des requêtes (recherches, modification etc, point sur l'API prévu 
ultérieurement). Il est à noté que le panneau de gauche est doté d'une autocomplétion
pour les fonctions et configurations standards dans elasticsearch.

Le panneau de droite est le \textbf{panneau de réponse} aux requêtes. Les informations
nous parviennent en JSON.

\section{La théorie}

\subsection{Approximation et comparaison avec le modèle relationnel}
La comparaison entre Elasticsearch et une base de données n'est pas forcement heureuse,
c'est un moteur de recherche (d'indexation). Il utilise donc la notion d'index   
qu'on peut cependant assez facilement comparer au modèle relationnel.

Elasticsearch s'organise autour d'index que l'on peut comparer aux bases (de données)
dans le modèle relationnel, un index peut utiliser plusieurs types (dans notre projet
nous aurions pu différencier les logs firewall des logs \textit{states} en utilisant 
les types), les types s'apparentent aux tables dans le modèle relationnel. 
Chaque enregistrement d'Elasticsearch est effectué sous forme document. Les documents
(qui ont un type, éventuellement type par défaut), un document peut être comparé 
à une ligne, ou un enregistrement. Ces lignes sont constitués de colonnes, appellées
champs (ou fields) dans Elasticsearch.


{\Huge NEED image}


\section{L'infrastructure}

\subsection{Le tunning}
Voici quelques conseilles qui sont applicables pratiquement dans toutes les situations
pour une utilisation optimale de Elasticsearch.

\subsubsection{Ne pas utiliser la swap}
Il est très fréquent (et souvent nécessaire) de formater une partition de swap pour
que le système puisse optimiser son fonctionnement. C'est très pratique pour ne pas
saturer la mémoire RAM de nos machines de bureau, notamment quand on voit la consommation
pantagruélique de certains navigateurs internet récents. Les fichiers qui ne sont 
susceptible de ne pas être utilisé avant un long moment sont parfois stocké sur le
disque dur afin de libérer de l'espace pour d'autres applications, la swap est
également utilisé lorsque l'on met un ordinateur en veille \ldots

La situation n'est pas la même sur un serveur. Ici nous sommes relativement maitre
de notre environnement, et de plus nous voulons que le service Elasticsearch soit 
le plus véloce possible, pour se faire il faut au contraire l'empêcher au maximum 
d'utiliser la partition de swap (forcément plus lente).

Il existe plusieurs façon de faire (y compris ne pas utiliser de partition de swap)
celle que j'ai choisie d'utiliser est de modifier la variable \ipath{vm.swapiness}
dans le fichier \ipath{/etc/sysctl.conf}. La swapiness représente le pourcentage
de mémoire RAM restant à partir duquel on commence à envoyer de informations en
swap.

\begin{lstlisting}[style=code,label={lst:configswapiness},caption={Configuration swapiness}]
vm.swapiness = 2
swapoff -a
swapon -a
\end{lstlisting}
Il existe deux méthodes pour que le changement de swapiness soit pris en compte :
redémarrer la machine ou bien désactiver puis réactiver la swap, via les commandes
swapon, swapoff. Utiliser la commande swapoff est également une mesure radicale à 
notre problème.

\subsubsection{Utiliser une quantité de RAM raisonné}
Elasticsearch est limité par Java. Avant de parler de ces limites, il faut rappeler 
que Elasticsearch est un front-end à Apache Lucene. Lucene est conçu pour tirer 
parti très efficacement du cache des système de fichiers (probablement ext4 si 
vous utilisez Debian), qui sont en définitif, gérer par le 
noyau\footnote{https://www.elastic.co/guide/en/elasticsearch/guide/current/\_limiting\_memory\_usage.html}.
Il est conseillé par la documentation de donner au maximum 50\% de la mémoire RAM
disponible à Elasticsearch, le reste étant dévouer à lucène et au bon fonctionnement
du système.
Dans notre installation dont nous parlerons plus en détail ultérieurement, nous 
avons choisi de nous réserver une bonne marge de manœuvre puisqu'un redis et un Logstash
minimalistes tournent en sus sur la machine hébergeant Elasticsearch.

Cependant cette valeur de 50\% n'a de sens que si Elasticsearch consomme moins de 
32Go de RAM, en effet, en allouer plus devient contreproductif puisque jusqu'à 32Go
la machine virtuelle Java (JVM) \textit{compresse} les adresses des pointeurs, 
(tant qu'on reste sous la limite des 32Go de RAM on peut continuer à utiliser les 
adresses mémoires sur 4 octets), après, la consommation de mémoire explose et le
\textit{garbage collector} devient bien moins efficace.

Pour les machines possédant une énorme quantité de mémoire RAM (128Go à 1To)
il conseiller pour optimiser le fonctionnement de la machine de faire tourner plusieurs
noeuds d'Elasticsearch dessus (attention aux entrées sortie et à l'utilisation processeur).

\subsection{Faire du nettoyage régulièrement}
Plus Elasticsearch agrège des données plus il s'empâte, ce phénomène est inévitable 
sur le long terme. Les contre-mesures sont de scale-out (monter à l'échelle horizontalement)
en rajoutant de nouveaux nœuds à notre cluster elastic search. On s'appliquera à 
manager les shards de façon optimisé bref à faire du fine tuning.

Pour éviter ce ralentissement la solution la plus radicale reste de supprimer les 
données. Justement, dans le cadre de notre projet, nous n'avons pas besoin de conserver 
toutes les données sur le long terme. Nous avons donc décider de supprimer les logs 
de changement d'état des par-feu tous les 4 jours. Ces logs peuvent représenter 
jusqu'à 30Go de données journalières. 
Pour ce faire nous utiliserons un tâche \textbf{cron} couplé à un script bash 
\ref{lst:scriptdelindex} tirant parti de l'API d'Elasticsearch dont nous parlerons 
plus bas. Pour indication, les index de firewall son supprimés tous les 4 jours, 
(une requête judiciaire/alerte sécurité arrive en général en moins de 3 jours).\\ 
Les logs sont de toute façon également conservés ailleurs pour se soumettre aux 
imperatifs judiciaires. Les index d'état (intéressants pour établir des statistiques)
sont conservés 1 mois.\\
Remarque sur la commande curl et son utilisation dans cron

\begin{lstlisting}[style=code,label={lst:curlexemple},caption={Extrait de notre script \ref{lst:scriptdelindex}}]
curl -sS -XDELETE $blade:$port/$target-$d
\end{lstlisting}

On remarque ici l'utilisation de l'option -sS pour \textit{silent, Show errors}.
Ainsi cron n'est pas importuné par les retour sur la sortie standard cela permet
également, en ajoutant la directive \textbf{MAILTO: mail@example.fr} de renvoyer
la sortie d'erreur vers mail@example.fr. Cela nécessite évidemment d'avoir configurer
un serveur mail sur notre machine, par défaut sur Debian, Exim (dpkg-reconfigure 
exim-config).

Concernant -XDELETE c'est une utilisation de l'API REST décrite plus bas.

Une des stratégies préconisé dans le cas où l'on souhaite conserver des données sur
le long terme alors qu'on en a seulement un besoin d'accès et d'analyse ponctuel ;
consiste à les enregistrer dans des fichiers séparés (output Logstash) et de les 
faire ingérer à un cluster Elasticsearch dimesinonné en conséquence le moment venu.



\section{Les API Elasticsearch}
Elasticsearch est énorme, mais être assez facilement utilisable par le 
plus grand nombre, des \gls{API} \emph{optimisées} pour chaque tâches ont été conçues.

\subsection{API REST}
Cette API sert à la communication avec Elastisearch, comme toutes les API REST elle
utilise les méthodes HTTP, ici : GET, POST, PUT et DELETE et s'appuie ensuite sur l'architecture d'Elasticsearch.

\textbf{{\color{grey}http://host:port}/[{\color{red}index}]/[{\color{cyan}type}]/[{\color{yellow}\_action/id}]}\\[5mm]
Imaginons que dans un projet fictif, nous souhaitions référencer des tweets.
On pourrait procéder comme suit pour ajouter le premier.

\textbf{PUT  {\color{grey} http://100.127.255.1:9200}/{\color{red}twitter}/{\color{cyan}tweet}/{\color{yellow}1}}

\begin{lstlisting}[style=code,label={lst:RESTexemple1curl},caption={Avec curl}]
curl -XPUT http://100.127.255.1:9200/twitter/tweet/1
\end{lstlisting}
Voici le résultat en utilisant curl, directement en ligne de commande, par 
navigateur, \ldots

\begin{lstlisting}[style=code,label={lst:RESTexemple1sense},caption={Avec Sense}]
PUT /twitter/tweet/1
\end{lstlisting}

Voici la syntaxe que nous obtiendrions en utilisant Sense, puisque notre serveur 
et notre port sont déjà renseignés, la syntaxe est bien plus courte.

La directive PUT est utilisé pour renseigner de nouvelles informations dans Elasticsearch.


Dans notre projet d'analyse de logs, il est fréquent que nous dussions supprimer 
des index, notamment dans le cas du paramétrage des \emph{mappings}, mais également
pour soulager notre infrastructure du poids des logs de firewall (~20-30Go/jours).\\

\textbf{DELETE  {\color{grey} http://100.127.255.1:9200}/{\color{red}twitter}/}\\

Si nous avions un index twitter journalier il serait possible d'utiliser une commande
très similaire pour supprimer tous les indexs d'un seul coup :\\

\textbf{DELETE  {\color{grey} http://100.127.255.1:9200}/{\color{red}twitter*}}\\

La directive DELETE est utilisé pour supprimer des informations d'Elasticsearch.\\


Enfin la directive GET qui sert à récupérer des information, à tout niveaux, index,
type, mapping, type par défaut \ldots, en revanche il faut avoir un identifiant exact,
ce n'est pas un outils de recherche (abordé dans la section suivante).\\[5mm]
\textbf{GET  {\color{grey} http://100.127.255.1:9200}/{\color{red}twitter}/{\color{cyan}tweet}/{\color{yellow}1}}\\

Les information récupérées le sont en JSON.

\subsection{Les API de recherche}
DSL pour Domain Specific Language, parce que Elasticsearch est avant tout un moteur 
de recherche, il dispose de puissantes fonctionnalités de recherche. Il dispose donc
de son propre langage d'interrogation le QueryDSL. C'est loin d'être un cas unique,
par exemple Puppet dispose également de son propre langage de configuration.

Il existe plusieurs API (ou méthodes) de recherche dans Elasticsearch nous les  
détaillerons plus en détail après avoir expliquer le fonctionnement général d'une
recherche dans Elasticsearch.

La recherche dans Elasticsearch est particulièrement efficace, car Elasticsearch 
indexe tout le contenu de ses documents (il indexe chaque field, en fonction d'un
mapping (discuté plus bas)).
C'est pour permettre l'indexation qu'Elasticsearch utilise du JSON structuré.



\subsubsection{Empty Search}
C'est la forme la plus basique de l'API de recherche, on ne spécifie pas de requête
spécifique. Comprendre le fonctionnement et les possiblité de cette API basique 
permettra d'utiliser plus efficacement SearchLite, qui en est l'évolution directe.


\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample1},caption={le "Hello World" de la recherche}]
GET /_search
\end{lstlisting}

Cette requête retourne tous les documents, de tous les index du cluster duquel nous
sommes membre.

\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample2},caption={Réponse type à notre requête précédente}]
{
    "took": 798,
    "timed_out": false,
    "_shards": {
        "total": 201,
        "successful": 201,
        "failed": 0
    },
    "hits": {
        "total": 353585048,
        "max_score": 1,
        "hits": [
        {
            "_index": ".kibana",
            "_type": "visualization",
            "_id": "Top5-nat-firewall-router",
            "_score": 1,
            "_source": {
                "title": "Top5 nat-firewall router",
                "visState": "{\"type\":\"histogram\",\"params\":{\"shareYAxis\":true,\"addTooltip\":true,\"addLegend\":true,\"mode\":\"stacked\",\"defaultYExtents\":false},\"aggs\":[{\"id\":\"1\",\"type\":\"count\",\"schema\":\"metric\",\"params\":{}},{\"id\":\"2\",\"type\":\"terms\",\"schema\":\"group\",\"params\":{\"field\":\"IPnat\",\"size\":5,\"order\":\"desc\",\"orderBy\":\"1\"}}],\"listeners\":{}}",
                "description": "",
                "version": 1,
                "kibanaSavedObjectMeta": {
                "searchSourceJSON": "{\"index\":\"firewall-*\",\"query\":{\"query_string\":{\"query\":\"*\",\"analyze_wildcard\":true}},\"filter\":[]}"
                }
            }
        },
        .... 9 Autres ...
    }
}
\end{lstlisting}

Quelques explications :

\paragraph{hits}
L'élément hits contient des informations sur la requête et les réponse à la requête.
\textit{total} représente le nombre total de documents retournés pour cette requête, ici le 
nombre total de documents indexés: 353585048. 
Cela signifie qu'au moment de la requête il y avait environ 353 millions de lignes
de logs indexés dans notre Elasticsearch au moment de la requête.

Les réponses à la requête nous sont renvoyées dans l'array \textit{hits}, par défaut
seul les 10 premiers documents satisfaisant notre requête nous sont renvoyés 
(comme il n'y avait pas de requête, simplement les 10 premiers documents).

Les documents renvoyés dans l'array sont classés en fonction de leur \_score, une 
fois encore, puisque nous n'avons rien précisé dans notre requête, tous les résultats 
nous sont renvoyés avec le score 1.

On notera que le \ipath{max\_score}, score maximum obtenu lors de la requête.

Enfin on remarque que le source (tous les champs indexés) de chaque document est présent
dans la réponse à la requête.

\paragraph{took}
Took est le temps en millisecondes pris pour effectué cette requête, ici 798

\paragraph{shard}
L'élément \_shards, nous indique le nombre de shards utilisé lors de la requête. 
Dans combien de shards tout c'est bien passé, dans combien il y a eu des erreurs,
les erreurs sont très peu probables, cela se produit généralement sur un cluster 
de plusieurs machines, lorsque plusieurs d'entre elles sont inacessibles (il faut 
que les primary et replica d'un shard soient inaccessible en même temps).

\paragraph{timeout}
Il est possible d'effectuer une recherche \textit{par timeout}, cela signifie que 
Elasticsearch va effectuer sa recherche de façon classique, mais que lorsque le temps
nécessaire à la recherche dépassera un temps déterminé, il renvera les informations 
qu'il a eu le temps de rassembler, toujours dans l'ordre qui lui semble le plus pertinant
(ordonné par score). Attention cependant, cela ne nous absouds pas pour autant du
coût de la recherche. Si les shards renvoient bien les résultats pertinents au moment
souhaité, cela n'arrête pas pour autant la requête qui finira de s'executer en arrière
plan.

\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample3},caption={Une recherche "vide" avec timeout}]
GET /_search?timeout=10ms
\end{lstlisting}


\paragraph{Recherche multi-index et multitype}
La recherche multi-index et multitype est toujours possible comme dans l'API REST

\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample4},caption={Une recherche multi-index ...}]
GET /gb,us/_search
GET /g*,u*/_search
GET /gb,us/user,tweet/_search
\end{lstlisting}

\paragraph{Pagination}
Par défaut lors d'une requête Elasticsearch renvoit seulement les 10$^{ers}$ résultats.
Il est biensure possible de paramétrer cela, pour afficher plus de résultats, et pas
forcément les plus pertinents (ceux qui présente le score le plus élevé).\\
\textbf{size} permet d'indiquer le nombre de résultats souhaités\\
\textbf{from} permet d'indiquer le nombre de résultats que l'on souhaite sauter.

\begin{lstlisting}[style=code,label={lst:APIsearchemptyexample4},caption={Pagination}]
GET /_search?size=5&from=10
\end{lstlisting}


\subsubsection{Search Lite}
Comme expliqué avant il existe deux forme d'API de recherche. L'API lite avec requête
en chaine de caractères \textit{(string query)} et l'API \textit{"full body request"},
qui nécessite comme corps de la requête, du JSON.

Pour utiliser la recherche SearchLite, nécessite simple d'ajouter en sus de notre
empty search \emph{?q=} et la requête. Attention si vous utilisez cette API avec 
curl il pourrait être nécessaire d'utiliser la syntaxe http (\%2B pour + par exemple).

\begin{lstlisting}[style=code,label={lst:APIsearchliteexample1},caption={Exemples simples}]
GET /_search?q=epinal
GET /state-2015.05.22/_search?q=epinal
\end{lstlisting}

Ici on cherche le terme \emph{epinal} dans tous les champs, c'est par fois utile,
mais dans de nombreux cas nous connaissons déjà le nom du champ (cf \hyperref[lst:grokregex1]{Logstash}) dans
lequel nous souhaitons avoir le terme. 

Pour se faire il suffit d'utiliser la syntaxe suivante : 
\begin{lstlisting}[style=code,label={lst:APIsearchliteexample2},caption={Choix du champ}]
GET /_search?q=logsource:epinal
\end{lstlisting}

Bien plus intéressant, il est possible d'imposer des conditions à remplir ie: doit
contenir le terme suivant, ou au contraire ne doit \textbf{pas} contenir le terme 
suivant.

\begin{lstlisting}[style=code,label={lst:APIsearchliteexample3},caption={Conditions must (not) match}]
GET /_search?q=+logsource:*epinal* -logsource:sw*
\end{lstlisting}

Dans l'exemple précédant on souhaite chercher les équipement réseaux situés à epinal
mais pas les switchs.
L'utilisation des + et - change vraiment le sens de la requête, dans la précédante
sans les symboles, la présence ou non augmentait la pertinence des réponses contenant
le terme recherché, mais n'était pas discriminante.
Avec ces symboles, on exclu les réponses qui ne se conforment pas à nos exigences.


La précense des \textbf{*} sera explicité dans la partie sur la recherche full text
{\scriptsize \textit{(prise d'Aspirine\texttrademark conseillée)}}.


Il existe un autre moyen d'influencer la pertinence des résultats (de faire remonter
en haut de liste ce qui nous intéresse le plus).
Cela est particulièrement pratique dans les longues requêtes.
Il s'agit de l'opérateur \textbf{\^} qu'on n'utilise en général en conjonction de
parenthèses (qui servent simplement à faire des groupes).


\begin{lstlisting}[style=code,label={lst:APIsearchliteexample4},caption={Modifier la pertinence}]
GET /_search?q=+logsource:*epinal* -logsource:sw* (timestamp:May)^10 Power
\end{lstlisting}
Dans cette requête nous cherchons toujours des équipements non switch situés à Epinal.
Nous somme cette fois ci très intéressés par ce qui s'est passé en Mai et d'autant
plus si cela concerne un problème d'alimentation éléctrique.

Concernant la gestion du temps, et des timestamp, nous allons voir une propriété 
intéressante d'Elasticsearch lorsque le mapping de l'index est bien réalisé.
Il est capable de \textit{s'orienter} dans le temps à partir d'un champ texte.
Cela n'est pas forcément très utile si l'on utilise Kibana, puisque son interface
nous permet très facilement d'être plus précis, mais cela laisse imaginer les possiblités
d'Elasticsearch.


\begin{lstlisting}[style=code,label={lst:APIsearchliteexample5},caption={Le temps dans SearchLite}]
GET /_search?q=+logsource:*epinal* -logsource:sw* (timestamp:>Jun)^10 Power
GET /_search?q=+logsource:*epinal* -logsource:sw* (timestamp:=<Jun)^10 Power
\end{lstlisting}

SearchLite accepte les opérateur $< > =< =>$ et Elasticsearch est capable de les 
interprété pour peu que le champ soit \textit{mappé comme date}(cf Mapping).

Il est possible d'utiliser les opérateurs logiques \textbf{OR} et \textbf{AND} 
dont l'utilisation est assez évidante \ldots
\begin{lstlisting}[style=code,label={lst:APIsearchliteexample6},caption={Opérateurs logiques}]
+IPoutside:"8.8.8.8" +IPnat:"8.8.4.4" +(portnat:"37657" OR portnat:"19474")
\end{lstlisting}




\subsubsection{Full-Body Search et QueryDSL}

\section{Le mapping et l'analyse}

